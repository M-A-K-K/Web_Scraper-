{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "# Path to your WebDriver executable\n",
    "webdriver_path = 'D:/Internship_Developers_den/web_scraping/folder_driver/chromedriver-win64/chromedriver.exe'\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Uncomment if you want to run it headlessly\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(webdriver_path), options=chrome_options)\n",
    "\n",
    "# Function to attempt element location with retries using CSS selector\n",
    "def attempt_element_locate(selector, retries=5, wait_time=30):\n",
    "    attempt = 0\n",
    "    while attempt < retries:\n",
    "        try:\n",
    "            element = WebDriverWait(driver, wait_time).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, selector))\n",
    "            )\n",
    "            return element\n",
    "        except (NoSuchElementException, TimeoutException) as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            attempt += 1\n",
    "    raise Exception(f\"Failed to locate element with CSS Selector: {selector} after {retries} attempts\")\n",
    "\n",
    "# Function to extract text from an element using a CSS selector\n",
    "def extract_text_from_selector(css_selector, retries=5, wait_time=30):\n",
    "    try:\n",
    "        element = attempt_element_locate(css_selector, retries, wait_time)\n",
    "        return element.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text: {e}\")\n",
    "        return \"Text not found\"\n",
    "\n",
    "# Function to extract image URL using a CSS selector\n",
    "def extract_image_url_from_selector(css_selector, retries=5, wait_time=30):\n",
    "    try:\n",
    "        img_element = attempt_element_locate(css_selector, retries, wait_time)\n",
    "        return img_element.get_attribute('src')\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting image URL: {e}\")\n",
    "        return \"Image URL not found\"\n",
    "\n",
    "# Function to extract all image URLs from a parent div\n",
    "def extract_all_images_from_div(parent_css_selector, retries=5, wait_time=30):\n",
    "    try:\n",
    "        parent_div = attempt_element_locate(parent_css_selector, retries, wait_time)\n",
    "        img_elements = parent_div.find_elements(By.TAG_NAME, 'img')\n",
    "        image_urls = [img.get_attribute('src') for img in img_elements if img.get_attribute('src')]\n",
    "        return image_urls\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting images from div: {e}\")\n",
    "        return []\n",
    "\n",
    "# Function to download an image from a URL and save it as PNG\n",
    "def download_image(image_url, output_path):\n",
    "    try:\n",
    "        print(f\"Attempting to download image from: {image_url}\")\n",
    "        response = requests.get(image_url, stream=True)\n",
    "        response.raise_for_status()  # Check if the request was successful\n",
    "        with open(output_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        print(f\"Image downloaded successfully: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image: {e}\")\n",
    "\n",
    "# Function to download a file from a URL\n",
    "def download_file(file_url, output_path):\n",
    "    try:\n",
    "        print(f\"Attempting to download file from: {file_url}\")\n",
    "        response = requests.get(file_url, stream=True)\n",
    "        response.raise_for_status()  # Check if the request was successful\n",
    "        with open(output_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        print(f\"File downloaded successfully: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file: {e}\")\n",
    "\n",
    "# URL of the page you want to scrape\n",
    "url = 'https://www.molteni.it/ap/product/d1542'\n",
    "\n",
    "# Open the product page\n",
    "driver.get(url)\n",
    "\n",
    "# Define the CSS selectors\n",
    "h1_selector = 'body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section:nth-child(1) > div > article > div.block-text-img-text.animation-fade-in > div > div > div.block-info-product__top.padding-line-element > a > h1'\n",
    "img_selector = 'body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section:nth-child(1) > div > article > div.block-text-img-img > div.animation-mask.p81 > div > a > img'\n",
    "h3_selector = 'body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section:nth-child(1) > div > article > div.block-text-img-text.animation-fade-in > div > div > h3'\n",
    "div_selector_1 = '#block-0 > div > div'\n",
    "div_selector_2 = '#block-2 > div > div'\n",
    "img_selector_2 = '#block-4 > div > div > div.col-8.block-text-img-img.is-768 > div > img'\n",
    "div_selector_3 = '#block-5 > div > div'\n",
    "file_selector = '#specs > div > div.row.product-specs-row > div:nth-child(3) > a'\n",
    "\n",
    "# Extract the <h1> text\n",
    "h1_text = extract_text_from_selector(h1_selector)\n",
    "print(f\"Extracted <h1> text: {h1_text}\")\n",
    "\n",
    "# Create directory based on <h1> text\n",
    "h1_folder_name = h1_text.replace('/', '-').replace('\\\\', '-')  # Sanitize folder name\n",
    "product_folder_path = os.path.join(h1_folder_name)\n",
    "if not os.path.exists(product_folder_path):\n",
    "    os.makedirs(product_folder_path)\n",
    "\n",
    "# Extract the image URL from the primary image selector\n",
    "img_url = extract_image_url_from_selector(img_selector)\n",
    "print(f\"Extracted image URL: {img_url}\")\n",
    "\n",
    "# Extract the <h3> text\n",
    "h3_text = extract_text_from_selector(h3_selector)\n",
    "print(f\"Extracted <h3> text: {h3_text}\")\n",
    "\n",
    "# Extract all image URLs from the specified divs\n",
    "image_urls_div_1 = extract_all_images_from_div(div_selector_1)\n",
    "print(f\"Extracted image URLs from div #block-0: {image_urls_div_1}\")\n",
    "\n",
    "image_urls_div_2 = extract_all_images_from_div(div_selector_2)\n",
    "print(f\"Extracted image URLs from div #block-2: {image_urls_div_2}\")\n",
    "\n",
    "# Extract the image URL from #block-4\n",
    "img_url_2 = extract_image_url_from_selector(img_selector_2)\n",
    "print(f\"Extracted image URL from #block-4: {img_url_2}\")\n",
    "\n",
    "# Extract all image URLs from #block-5\n",
    "image_urls_div_3 = extract_all_images_from_div(div_selector_3)\n",
    "print(f\"Extracted image URLs from div #block-5: {image_urls_div_3}\")\n",
    "\n",
    "# List all image URLs to download\n",
    "all_image_urls = [img_url] + [img_url_2] + image_urls_div_1 + image_urls_div_2 + image_urls_div_3\n",
    "print(f\"All image URLs to download: {all_image_urls}\")\n",
    "\n",
    "# Download images directly in the product folder\n",
    "for idx, img_url in enumerate(all_image_urls):\n",
    "    if img_url and img_url.startswith('http'):\n",
    "        img_file_path = os.path.join(product_folder_path, f'image_{idx + 1}.png')\n",
    "        download_image(img_url, img_file_path)\n",
    "\n",
    "# Extract file download link and download the file\n",
    "file_element = attempt_element_locate(file_selector)\n",
    "if file_element:\n",
    "    file_link = file_element.get_attribute('href')\n",
    "    if file_link and file_link.startswith('http'):\n",
    "        print(f\"File link extracted: {file_link}\")\n",
    "        download_file(file_link, os.path.join(product_folder_path, 'description.pdf'))\n",
    "    else:\n",
    "        print(\"No valid file link found.\")\n",
    "else:\n",
    "    print(\"File element not found.\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "# Path to your WebDriver executable\n",
    "webdriver_path = 'D:/Internship_Developers_den/web_scraping/folder_driver/chromedriver-win64/chromedriver.exe'\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Uncomment if you want to run it headlessly\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(webdriver_path), options=chrome_options)\n",
    "\n",
    "# URL to scrape\n",
    "url = 'https://www.molteni.it/ap/highlights'\n",
    "\n",
    "# Open the webpage\n",
    "driver.get(url)\n",
    "\n",
    "try:\n",
    "    # Wait until the section containing the articles is loaded\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    section = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section.product-category > div > div > div > section.content-block.catalog-list')))\n",
    "    \n",
    "    # Find all article tags within the section\n",
    "    articles = section.find_elements(By.TAG_NAME, 'article')\n",
    "    \n",
    "    # Loop through each article tag and find all <a> tags inside it\n",
    "    for article in articles:\n",
    "        links = article.find_elements(By.TAG_NAME, 'a')\n",
    "        for link in links:\n",
    "            # Print the href attribute of each <a> tag (which contains the URL)\n",
    "            print(link.get_attribute('href'))\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Loading the section took too long.\")\n",
    "except NoSuchElementException:\n",
    "    print(\"Could not find the required elements on the page.\")\n",
    "finally:\n",
    "    # Close the browser\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "# Path to your WebDriver executable\n",
    "webdriver_path = 'D:/Internship_Developers_den/web_scraping/folder_driver/chromedriver-win64/chromedriver.exe'\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Uncomment if you want to run it headlessly\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(webdriver_path), options=chrome_options)\n",
    "\n",
    "# URL of the page you want to scrape (all products page)\n",
    "main_url = 'https://www.molteni.it/ap/highlights'\n",
    "\n",
    "# Function to attempt element location with retries using CSS selector\n",
    "def attempt_element_locate(driver, selector, retries=5, wait_time=30):\n",
    "    attempt = 0\n",
    "    while attempt < retries:\n",
    "        try:\n",
    "            element = WebDriverWait(driver, wait_time).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, selector))\n",
    "            )\n",
    "            return element\n",
    "        except (NoSuchElementException, TimeoutException) as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            attempt += 1\n",
    "    raise Exception(f\"Failed to locate element with CSS Selector: {selector} after {retries} attempts\")\n",
    "\n",
    "# Function to extract all product links\n",
    "def get_product_links():\n",
    "    driver.get(main_url)\n",
    "    try:\n",
    "        # Wait until the section containing the articles is loaded\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        section = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section.product-category > div > div > div > section.content-block.catalog-list')))\n",
    "        \n",
    "        # Find all article tags within the section\n",
    "        articles = section.find_elements(By.TAG_NAME, 'article')\n",
    "        product_links = []\n",
    "        \n",
    "        # Loop through each article tag and find all <a> tags inside it\n",
    "        for article in articles:\n",
    "            links = article.find_elements(By.TAG_NAME, 'a')\n",
    "            for link in links:\n",
    "                href = link.get_attribute('href')\n",
    "                if href:\n",
    "                    product_links.append(href)\n",
    "        \n",
    "        return product_links\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"Loading the section took too long.\")\n",
    "        return []\n",
    "    except NoSuchElementException:\n",
    "        print(\"Could not find the required elements on the page.\")\n",
    "        return []\n",
    "\n",
    "# Function to scrape product details from each product page\n",
    "def scrape_product_page(product_url):\n",
    "    driver.get(product_url)\n",
    "    \n",
    "    # Define the CSS selectors\n",
    "    h1_selector = 'body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section:nth-child(1) > div > article > div.block-text-img-text.animation-fade-in > div > div > div.block-info-product__top.padding-line-element > a > h1'\n",
    "    img_selector = 'body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section:nth-child(1) > div > article > div.block-text-img-img > div.animation-mask.p81 > div > a > img'\n",
    "    h3_selector = 'body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section:nth-child(1) > div > article > div.block-text-img-text.animation-fade-in > div > div > h3'\n",
    "    div_selector_1 = '#block-0 > div > div'\n",
    "    div_selector_2 = '#block-2 > div > div'\n",
    "    img_selector_2 = '#block-4 > div > div > div.col-8.block-text-img-img.is-768 > div > img'\n",
    "    div_selector_3 = '#block-5 > div > div'\n",
    "    file_selector = '#specs > div > div.row.product-specs-row > div:nth-child(3) > a'\n",
    "\n",
    "    # Extract the <h1> text\n",
    "    h1_text = extract_text_from_selector(driver, h1_selector)\n",
    "    print(f\"Extracted <h1> text: {h1_text}\")\n",
    "\n",
    "    # Create directory based on <h1> text\n",
    "    h1_folder_name = h1_text.replace('/', '-').replace('\\\\', '-')  # Sanitize folder name\n",
    "    product_folder_path = os.path.join(h1_folder_name)\n",
    "    if not os.path.exists(product_folder_path):\n",
    "        os.makedirs(product_folder_path)\n",
    "\n",
    "    # Extract the image URL from the primary image selector\n",
    "    img_url = extract_image_url_from_selector(driver, img_selector)\n",
    "    print(f\"Extracted image URL: {img_url}\")\n",
    "\n",
    "    # Extract the <h3> text\n",
    "    h3_text = extract_text_from_selector(driver, h3_selector)\n",
    "    print(f\"Extracted <h3> text: {h3_text}\")\n",
    "\n",
    "    # Extract all image URLs from the specified divs\n",
    "    image_urls_div_1 = extract_all_images_from_div(driver, div_selector_1)\n",
    "    image_urls_div_2 = extract_all_images_from_div(driver, div_selector_2)\n",
    "    img_url_2 = extract_image_url_from_selector(driver, img_selector_2)\n",
    "    image_urls_div_3 = extract_all_images_from_div(driver, div_selector_3)\n",
    "\n",
    "    # List all image URLs to download\n",
    "    all_image_urls = [img_url] + [img_url_2] + image_urls_div_1 + image_urls_div_2 + image_urls_div_3\n",
    "    print(f\"All image URLs to download: {all_image_urls}\")\n",
    "\n",
    "    # Download images directly in the product folder\n",
    "    for idx, img_url in enumerate(all_image_urls):\n",
    "        if img_url and img_url.startswith('http'):\n",
    "            img_file_path = os.path.join(product_folder_path, f'image_{idx + 1}.png')\n",
    "            download_image(img_url, img_file_path)\n",
    "\n",
    "    # Extract file download link and download the file\n",
    "    file_element = attempt_element_locate(driver, file_selector)\n",
    "    if file_element:\n",
    "        file_link = file_element.get_attribute('href')\n",
    "        if file_link and file_link.startswith('http'):\n",
    "            download_file(file_link, os.path.join(product_folder_path, 'description.pdf'))\n",
    "        else:\n",
    "            print(\"No valid file link found.\")\n",
    "    else:\n",
    "        print(\"File element not found.\")\n",
    "\n",
    "# Helper functions for element extraction, image download, and file download\n",
    "def extract_text_from_selector(driver, css_selector, retries=5, wait_time=30):\n",
    "    try:\n",
    "        element = attempt_element_locate(driver, css_selector, retries, wait_time)\n",
    "        return element.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text: {e}\")\n",
    "        return \"Text not found\"\n",
    "\n",
    "def extract_image_url_from_selector(driver, css_selector, retries=5, wait_time=30):\n",
    "    try:\n",
    "        img_element = attempt_element_locate(driver, css_selector, retries, wait_time)\n",
    "        return img_element.get_attribute('src')\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting image URL: {e}\")\n",
    "        return \"Image URL not found\"\n",
    "\n",
    "def extract_all_images_from_div(driver, parent_css_selector, retries=5, wait_time=30):\n",
    "    try:\n",
    "        parent_div = attempt_element_locate(driver, parent_css_selector, retries, wait_time)\n",
    "        img_elements = parent_div.find_elements(By.TAG_NAME, 'img')\n",
    "        image_urls = [img.get_attribute('src') for img in img_elements if img.get_attribute('src')]\n",
    "        return image_urls\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting images from div: {e}\")\n",
    "        return []\n",
    "\n",
    "def download_image(image_url, output_path):\n",
    "    try:\n",
    "        print(f\"Attempting to download image from: {image_url}\")\n",
    "        response = requests.get(image_url, stream=True)\n",
    "        response.raise_for_status()  # Check if the request was successful\n",
    "        with open(output_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        print(f\"Image downloaded successfully: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image: {e}\")\n",
    "\n",
    "def download_file(file_url, output_path):\n",
    "    try:\n",
    "        print(f\"Attempting to download file from: {file_url}\")\n",
    "        response = requests.get(file_url, stream=True)\n",
    "        response.raise_for_status()  # Check if the request was successful\n",
    "        with open(output_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        print(f\"File downloaded successfully: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file: {e}\")\n",
    "\n",
    "# Main script execution\n",
    "product_links = get_product_links()\n",
    "\n",
    "if product_links:\n",
    "    for product_link in product_links:\n",
    "        scrape_product_page(product_link)\n",
    "else:\n",
    "    print(\"No product links found.\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "# Path to your WebDriver executable\n",
    "webdriver_path = 'D:/Internship_Developers_den/web_scraping/folder_driver/chromedriver-win64/chromedriver.exe'\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Uncomment if you want to run it headlessly\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(webdriver_path), options=chrome_options)\n",
    "\n",
    "# URL of the page you want to scrape (all products page)\n",
    "main_url = 'https://www.molteni.it/ap/highlights'\n",
    "\n",
    "# Function to attempt element location with retries using CSS selector\n",
    "def attempt_element_locate(driver, selector, retries=5, wait_time=30):\n",
    "    attempt = 0\n",
    "    while attempt < retries:\n",
    "        try:\n",
    "            element = WebDriverWait(driver, wait_time).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, selector))\n",
    "            )\n",
    "            return element\n",
    "        except (NoSuchElementException, TimeoutException) as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            attempt += 1\n",
    "    raise Exception(f\"Failed to locate element with CSS Selector: {selector} after {retries} attempts\")\n",
    "\n",
    "# Function to extract all product links\n",
    "def get_product_links():\n",
    "    driver.get(main_url)\n",
    "    try:\n",
    "        # Wait until the section containing the articles is loaded\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        section = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section.product-category > div > div > div > section.content-block.catalog-list')))\n",
    "        \n",
    "        # Find all article tags within the section\n",
    "        articles = section.find_elements(By.TAG_NAME, 'article')\n",
    "        product_links = []\n",
    "        \n",
    "        # Loop through each article tag and find all <a> tags inside it\n",
    "        for article in articles:\n",
    "            links = article.find_elements(By.TAG_NAME, 'a')\n",
    "            for link in links:\n",
    "                href = link.get_attribute('href')\n",
    "                if href:\n",
    "                    product_links.append(href)\n",
    "        \n",
    "        return product_links\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"Loading the section took too long.\")\n",
    "        return []\n",
    "    except NoSuchElementException:\n",
    "        print(\"Could not find the required elements on the page.\")\n",
    "        return []\n",
    "\n",
    "# Function to scrape product details from each product page\n",
    "def scrape_product_page(product_url):\n",
    "    driver.get(product_url)\n",
    "    \n",
    "    # Define the CSS selectors\n",
    "    h1_selector = 'body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section:nth-child(1) > div > article > div.block-text-img-text.animation-fade-in > div > div > div.block-info-product__top.padding-line-element > a > h1'\n",
    "    h3_selector = 'body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section:nth-child(1) > div > article > div.block-text-img-text.animation-fade-in > div > div > h3'\n",
    "    file_selector = '#specs > div > div.row.product-specs-row > div:nth-child(3) > a'\n",
    "\n",
    "    # Extract the <h1> text\n",
    "    h1_text = extract_text_from_selector(driver, h1_selector)\n",
    "    print(f\"Extracted <h1> text: {h1_text}\")\n",
    "\n",
    "    # Sanitize folder name\n",
    "    h1_folder_name = h1_text.replace('/', '-').replace('\\\\', '-').replace(':', '-').replace('*', '-').replace('?', '-').replace('\"', '-').replace('<', '-').replace('>', '-').replace('|', '-')\n",
    "    product_folder_path = os.path.join(h1_folder_name)\n",
    "    print(f\"Creating directory at path: {product_folder_path}\")\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(product_folder_path):\n",
    "            os.makedirs(product_folder_path)\n",
    "        print(f\"Directory created successfully: {product_folder_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating directory: {e}\")\n",
    "        return\n",
    "\n",
    "    # Extract the <h3> text\n",
    "    h3_text = extract_text_from_selector(driver, h3_selector)\n",
    "    print(f\"Extracted <h3> text: {h3_text}\")\n",
    "\n",
    "    # Extract all image URLs from the entire page (limited to the first 18)\n",
    "    all_image_urls = extract_all_images_from_page(driver)\n",
    "    print(f\"All image URLs to download: {all_image_urls}\")\n",
    "\n",
    "    # Download images directly in the product folder\n",
    "    for idx, img_url in enumerate(all_image_urls[:18]):\n",
    "        if img_url and img_url.startswith('http'):\n",
    "            img_file_path = os.path.join(product_folder_path, f'image_{idx + 1}.png')\n",
    "            download_image(img_url, img_file_path)\n",
    "\n",
    "    # Extract file download link and download the file\n",
    "    file_element = attempt_element_locate(driver, file_selector)\n",
    "    if file_element:\n",
    "        file_link = file_element.get_attribute('href')\n",
    "        if file_link and file_link.startswith('http'):\n",
    "            download_file(file_link, os.path.join(product_folder_path, 'description.pdf'))\n",
    "        else:\n",
    "            print(\"No valid file link found.\")\n",
    "    else:\n",
    "        print(\"File element not found.\")\n",
    "\n",
    "# Helper functions for element extraction, image download, and file download\n",
    "def extract_text_from_selector(driver, css_selector, retries=5, wait_time=30):\n",
    "    try:\n",
    "        element = attempt_element_locate(driver, css_selector, retries, wait_time)\n",
    "        return element.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text: {e}\")\n",
    "        return \"Text not found\"\n",
    "\n",
    "def extract_all_images_from_page(driver, retries=5, wait_time=30):\n",
    "    try:\n",
    "        # Retrieve all img elements on the page\n",
    "        img_elements = driver.find_elements(By.TAG_NAME, 'img')\n",
    "        image_urls = [img.get_attribute('src') for img in img_elements if img.get_attribute('src')]\n",
    "        return image_urls\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting images from page: {e}\")\n",
    "        return []\n",
    "\n",
    "def download_image(image_url, output_path):\n",
    "    try:\n",
    "        print(f\"Attempting to download image from: {image_url}\")\n",
    "        response = requests.get(image_url, stream=True)\n",
    "        response.raise_for_status()  # Check if the request was successful\n",
    "        with open(output_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        print(f\"Image downloaded successfully: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image: {e}\")\n",
    "\n",
    "def download_file(file_url, output_path):\n",
    "    try:\n",
    "        print(f\"Attempting to download file from: {file_url}\")\n",
    "        response = requests.get(file_url, stream=True)\n",
    "        response.raise_for_status()  # Check if the request was successful\n",
    "        with open(output_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        print(f\"File downloaded successfully: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file: {e}\")\n",
    "\n",
    "# Main script execution\n",
    "product_links = get_product_links()\n",
    "\n",
    "if product_links:\n",
    "    for product_link in product_links:\n",
    "        scrape_product_page(product_link)\n",
    "else:\n",
    "    print(\"No product links found.\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "# Path to your WebDriver executable\n",
    "webdriver_path = 'D:/Internship_Developers_den/web_scraping/folder_driver/chromedriver-win64/chromedriver.exe'\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Uncomment if you want to run it headlessly\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(webdriver_path), options=chrome_options)\n",
    "\n",
    "# URL of the page you want to scrape (all products page)\n",
    "main_url = 'https://www.molteni.it/ap/highlights'\n",
    "\n",
    "# Function to attempt element location with retries using CSS selector\n",
    "def attempt_element_locate(driver, selector, retries=5, wait_time=30):\n",
    "    attempt = 0\n",
    "    while attempt < retries:\n",
    "        try:\n",
    "            element = WebDriverWait(driver, wait_time).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, selector))\n",
    "            )\n",
    "            return element\n",
    "        except (NoSuchElementException, TimeoutException) as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            attempt += 1\n",
    "    raise Exception(f\"Failed to locate element with CSS Selector: {selector} after {retries} attempts\")\n",
    "\n",
    "# Function to extract all product links\n",
    "def get_product_links():\n",
    "    driver.get(main_url)\n",
    "    try:\n",
    "        # Wait until the section containing the articles is loaded\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        section = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section.product-category > div > div > div > section.content-block.catalog-list')))\n",
    "        \n",
    "        # Find all article tags within the section\n",
    "        articles = section.find_elements(By.TAG_NAME, 'article')\n",
    "        product_links = []\n",
    "        \n",
    "        # Loop through each article tag and find all <a> tags inside it\n",
    "        for article in articles:\n",
    "            links = article.find_elements(By.TAG_NAME, 'a')\n",
    "            for link in links:\n",
    "                href = link.get_attribute('href')\n",
    "                if href:\n",
    "                    product_links.append(href)\n",
    "        \n",
    "        return product_links\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"Loading the section took too long.\")\n",
    "        return []\n",
    "    except NoSuchElementException:\n",
    "        print(\"Could not find the required elements on the page.\")\n",
    "        return []\n",
    "\n",
    "# Function to scrape product details from each product page\n",
    "def scrape_product_page(product_url):\n",
    "    driver.get(product_url)\n",
    "    \n",
    "    # Define the CSS selectors\n",
    "    h1_selector = 'body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section:nth-child(1) > div > article > div.block-text-img-text.animation-fade-in > div > div > div.block-info-product__top.padding-line-element > a > h1'\n",
    "    h3_selector = 'body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section:nth-child(1) > div > article > div.block-text-img-text.animation-fade-in > div > div > h3'\n",
    "    file_selector = '#specs > div > div.row.product-specs-row > div:nth-child(3) > a'\n",
    "\n",
    "    # Extract the <h1> text\n",
    "    h1_text = extract_text_from_selector(driver, h1_selector)\n",
    "    print(f\"Extracted <h1> text: {h1_text}\")\n",
    "\n",
    "    # Sanitize folder name\n",
    "    h1_folder_name = h1_text.replace('/', '-').replace('\\\\', '-').replace(':', '-').replace('*', '-').replace('?', '-').replace('\"', '-').replace('<', '-').replace('>', '-').replace('|', '-')\n",
    "    product_folder_path = os.path.join(h1_folder_name)\n",
    "    print(f\"Creating directory at path: {product_folder_path}\")\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(product_folder_path):\n",
    "            os.makedirs(product_folder_path)\n",
    "        print(f\"Directory created successfully: {product_folder_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating directory: {e}\")\n",
    "        return\n",
    "\n",
    "    # Extract the <h3> text\n",
    "    h3_text = extract_text_from_selector(driver, h3_selector)\n",
    "    print(f\"Extracted <h3> text: {h3_text}\")\n",
    "\n",
    "    # Extract all image URLs from the page (limited to the first 18)\n",
    "    all_image_urls = extract_images_between_sections(driver, 'body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section:nth-child(1) > div', '#block-14 > div')\n",
    "    print(f\"All image URLs to download: {all_image_urls}\")\n",
    "\n",
    "    # Download images directly in the product folder\n",
    "    for idx, img_url in enumerate(all_image_urls[:18]):\n",
    "        if img_url and img_url.startswith('http'):\n",
    "            img_file_path = os.path.join(product_folder_path, f'image_{idx + 1}.png')\n",
    "            download_image(img_url, img_file_path)\n",
    "\n",
    "    # Extract file download link and download the file\n",
    "    file_element = attempt_element_locate(driver, file_selector)\n",
    "    if file_element:\n",
    "        file_link = file_element.get_attribute('href')\n",
    "        if file_link and file_link.startswith('http'):\n",
    "            download_file(file_link, os.path.join(product_folder_path, 'description.pdf'))\n",
    "        else:\n",
    "            print(\"No valid file link found.\")\n",
    "    else:\n",
    "        print(\"File element not found.\")\n",
    "\n",
    "# Helper functions for element extraction, image download, and file download\n",
    "def extract_text_from_selector(driver, css_selector, retries=5, wait_time=30):\n",
    "    try:\n",
    "        element = attempt_element_locate(driver, css_selector, retries, wait_time)\n",
    "        return element.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text: {e}\")\n",
    "        return \"Text not found\"\n",
    "\n",
    "def extract_images_between_sections(driver, start_selector, end_selector, retries=5, wait_time=30):\n",
    "    try:\n",
    "        # Retrieve the start and end elements\n",
    "        start_element = attempt_element_locate(driver, start_selector, retries, wait_time)\n",
    "        end_element = attempt_element_locate(driver, end_selector, retries, wait_time)\n",
    "\n",
    "        # Find all img elements on the page\n",
    "        img_elements = driver.find_elements(By.TAG_NAME, 'img')\n",
    "        image_urls = []\n",
    "        start_found = False\n",
    "        end_found = False\n",
    "\n",
    "        for img in img_elements:\n",
    "            # Check if the image is located within the start section\n",
    "            parent_element = img.find_element(By.XPATH, '..')  # Find the parent of the img\n",
    "            parent_id = parent_element.get_attribute('id')\n",
    "\n",
    "            if start_element in parent_element.find_elements(By.XPATH, '..'):\n",
    "                start_found = True\n",
    "\n",
    "            if start_found and not end_found:\n",
    "                # Add image URL to the list\n",
    "                image_url = img.get_attribute('src')\n",
    "                if image_url:\n",
    "                    image_urls.append(image_url)\n",
    "\n",
    "            if end_element in parent_element.find_elements(By.XPATH, '..'):\n",
    "                end_found = True\n",
    "                break\n",
    "\n",
    "        return image_urls\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting images from page: {e}\")\n",
    "        return []\n",
    "\n",
    "def download_image(image_url, output_path):\n",
    "    try:\n",
    "        print(f\"Attempting to download image from: {image_url}\")\n",
    "        response = requests.get(image_url, stream=True)\n",
    "        response.raise_for_status()  # Check if the request was successful\n",
    "        with open(output_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        print(f\"Image downloaded successfully: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image: {e}\")\n",
    "\n",
    "def download_file(file_url, output_path):\n",
    "    try:\n",
    "        print(f\"Attempting to download file from: {file_url}\")\n",
    "        response = requests.get(file_url, stream=True)\n",
    "        response.raise_for_status()  # Check if the request was successful\n",
    "        with open(output_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        print(f\"File downloaded successfully: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file: {e}\")\n",
    "\n",
    "# Main script execution\n",
    "product_links = get_product_links()\n",
    "\n",
    "if product_links:\n",
    "    for product_link in product_links:\n",
    "        scrape_product_page(product_link)\n",
    "else:\n",
    "    print(\"No product links found.\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is working for one product only in second category \n",
    "import os\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "# Path to your WebDriver executable\n",
    "webdriver_path = 'D:/Internship_Developers_den/web_scraping/folder_driver/chromedriver-win64/chromedriver.exe'\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Uncomment if you want to run it headlessly\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(webdriver_path), options=chrome_options)\n",
    "\n",
    "# URL of the page you want to scrape (specific product page)\n",
    "main_url = 'https://www.molteni.it/ap/product/intersection'\n",
    "\n",
    "# Open the webpage\n",
    "driver.get(main_url)\n",
    "\n",
    "def download_image(image_url, folder_path, image_name):\n",
    "    try:\n",
    "        # Get image content\n",
    "        response = requests.get(image_url, stream=True)\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "\n",
    "        # Define the path where the image will be saved\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "\n",
    "        # Save the image\n",
    "        with open(image_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                file.write(chunk)\n",
    "        print(f\"Saved image: {image_name}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {image_url}. Reason: {e}\")\n",
    "\n",
    "def download_file(file_url, folder_path, file_name):\n",
    "    try:\n",
    "        # Get file content\n",
    "        response = requests.get(file_url, stream=True)\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "\n",
    "        # Define the path where the file will be saved\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Save the file\n",
    "        with open(file_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                file.write(chunk)\n",
    "        print(f\"Saved file: {file_name}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {file_url}. Reason: {e}\")\n",
    "\n",
    "def extract_images_from_selector(selector, folder_path, image_counter):\n",
    "    try:\n",
    "        # Wait for the containers to be present\n",
    "        container_divs = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, selector))\n",
    "        )\n",
    "        \n",
    "        # Extract images from all containers\n",
    "        for container_div in container_divs:\n",
    "            # Find all images inside the container\n",
    "            all_images = container_div.find_elements(By.TAG_NAME, \"img\")\n",
    "            \n",
    "            # Loop through each found image and get the 'src' attribute\n",
    "            for img in all_images:\n",
    "                image_src = img.get_attribute('src')\n",
    "                image_name = f\"image_{image_counter}.png\"\n",
    "                download_image(image_src, folder_path, image_name)\n",
    "                image_counter += 1\n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(f\"No images found inside the container {selector} or timeout occurred.\")\n",
    "    \n",
    "    return image_counter\n",
    "\n",
    "try:\n",
    "    # Extract text from h1 tag inside a specific div\n",
    "    text_selector = \"body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section:nth-child(1) > div > article > div.block-text-img-text.animation-fade-in > div > div > div.block-info-product__top.padding-line-element\"\n",
    "    \n",
    "    try:\n",
    "        # Wait for the div to be present\n",
    "        info_div = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, text_selector))\n",
    "        )\n",
    "        \n",
    "        # Find the <a> tag inside the div\n",
    "        a_tag = info_div.find_element(By.TAG_NAME, \"a\")\n",
    "        \n",
    "        # Find the <h1> tag inside the <a> tag and get its text\n",
    "        h1_tag = a_tag.find_element(By.TAG_NAME, \"h1\")\n",
    "        h1_text = h1_tag.text.strip()\n",
    "        print(\"H1 Text:\", h1_text)\n",
    "        \n",
    "        # Create a directory with the H1 text as its name\n",
    "        folder_path = os.path.join(os.getcwd(), h1_text.replace('/', '_').replace('\\\\', '_'))  # Replace invalid characters\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"H1 tag not found inside the specified container or timeout occurred.\")\n",
    "        folder_path = os.getcwd()  # Use current directory if H1 text not found\n",
    "\n",
    "    # Extract images from all specified selectors and save to the created folder\n",
    "    selectors = [\n",
    "        \"body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section:nth-child(1)\",\n",
    "        \"#block-0\",\n",
    "        \"#block-1\",\n",
    "        \"#block-2\",\n",
    "        \"#block-3\",\n",
    "        \"#block-4\",\n",
    "        \"#block-5\",\n",
    "        \"#block-6\",\n",
    "        \"#block-7\",\n",
    "        \"#block-8\",\n",
    "        \"#block-9\",\n",
    "        \"#block-10\",\n",
    "        \"#block-11\"\n",
    "    ]\n",
    "    \n",
    "    image_counter = 1\n",
    "    for selector in selectors:\n",
    "        image_counter = extract_images_from_selector(selector, folder_path, image_counter)\n",
    "\n",
    "    # Download the file from the specified anchor tag\n",
    "    anchor_selector = \"#specs > div > div.row.product-specs-row > div:nth-child(3) > a\"\n",
    "    \n",
    "    try:\n",
    "        # Wait for the anchor tag to be present\n",
    "        anchor_tag = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, anchor_selector))\n",
    "        )\n",
    "        \n",
    "        # Get the URL from the href attribute\n",
    "        file_url = anchor_tag.get_attribute('href')\n",
    "        file_name = \"description.pdf\"  # Set filename for the downloaded file\n",
    "        \n",
    "        # Download the file\n",
    "        download_file(file_url, folder_path, file_name)\n",
    "    \n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(\"Anchor tag not found inside the specified container or timeout occurred.\")\n",
    "\n",
    "except (NoSuchElementException, TimeoutException) as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the browser window\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is working for Kitchen category and will get all products\n",
    "import os\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "# Path to your WebDriver executable\n",
    "webdriver_path = 'D:/Internship_Developers_den/web_scraping/folder_driver/chromedriver-win64/chromedriver.exe'\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Uncomment if you want to run it headlessly\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(webdriver_path), options=chrome_options)\n",
    "\n",
    "def download_image(image_url, folder_path, image_name):\n",
    "    try:\n",
    "        response = requests.get(image_url, stream=True)\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        with open(image_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                file.write(chunk)\n",
    "        print(f\"Saved image: {image_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {image_url}. Reason: {e}\")\n",
    "\n",
    "def download_file(file_url, folder_path, file_name):\n",
    "    try:\n",
    "        response = requests.get(file_url, stream=True)\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                file.write(chunk)\n",
    "        print(f\"Saved file: {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {file_url}. Reason: {e}\")\n",
    "\n",
    "def extract_images_from_selector(selector, folder_path, image_counter):\n",
    "    try:\n",
    "        container_divs = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, selector))\n",
    "        )\n",
    "        for container_div in container_divs:\n",
    "            all_images = container_div.find_elements(By.TAG_NAME, \"img\")\n",
    "            for img in all_images:\n",
    "                image_src = img.get_attribute('src')\n",
    "                image_name = f\"image_{image_counter}.png\"\n",
    "                download_image(image_src, folder_path, image_name)\n",
    "                image_counter += 1\n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(f\"No images found inside the container {selector} or timeout occurred.\")\n",
    "    return image_counter\n",
    "\n",
    "def get_product_links(base_url):\n",
    "    driver.get(base_url)\n",
    "    links = []\n",
    "    try:\n",
    "        product_elements = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section.product-category > div > div > div > section.content-block.catalog-list > article > a'))\n",
    "        )\n",
    "        for element in product_elements:\n",
    "            link = element.get_attribute('href')\n",
    "            if link:\n",
    "                links.append(link)\n",
    "    except (NoSuchElementException, TimeoutException) as e:\n",
    "        print(f\"An error occurred while fetching product links: {e}\")\n",
    "    return links\n",
    "\n",
    "def scrape_product_page(product_url):\n",
    "    driver.get(product_url)\n",
    "    try:\n",
    "        text_selector = \"body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section:nth-child(1) > div > article > div.block-text-img-text.animation-fade-in > div > div > div.block-info-product__top.padding-line-element\"\n",
    "        try:\n",
    "            info_div = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, text_selector))\n",
    "            )\n",
    "            a_tag = info_div.find_element(By.TAG_NAME, \"a\")\n",
    "            h1_tag = a_tag.find_element(By.TAG_NAME, \"h1\")\n",
    "            h1_text = h1_tag.text.strip()\n",
    "            print(\"H1 Text:\", h1_text)\n",
    "            folder_path = os.path.join(os.getcwd(), h1_text.replace('/', '_').replace('\\\\', '_'))\n",
    "            os.makedirs(folder_path, exist_ok=True)\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            print(\"H1 tag not found inside the specified container or timeout occurred.\")\n",
    "            folder_path = os.getcwd()\n",
    "\n",
    "        selectors = [\n",
    "            \"body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section:nth-child(1)\",\n",
    "            \"#block-0\",\n",
    "            \"#block-1\",\n",
    "            \"#block-2\",\n",
    "            \"#block-3\",\n",
    "            \"#block-4\",\n",
    "            \"#block-5\",\n",
    "            \"#block-6\",\n",
    "            \"#block-7\",\n",
    "            \"#block-8\",\n",
    "            \"#block-9\",\n",
    "            \"#block-10\",\n",
    "            \"#block-11\"\n",
    "        ]\n",
    "        image_counter = 1\n",
    "        for selector in selectors:\n",
    "            image_counter = extract_images_from_selector(selector, folder_path, image_counter)\n",
    "\n",
    "        anchor_selector = \"#specs > div > div.row.product-specs-row > div:nth-child(3) > a\"\n",
    "        try:\n",
    "            anchor_tag = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, anchor_selector))\n",
    "            )\n",
    "            file_url = anchor_tag.get_attribute('href')\n",
    "            file_name = \"description.pdf\"\n",
    "            download_file(file_url, folder_path, file_name)\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            print(\"Anchor tag not found inside the specified container or timeout occurred.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the product page {product_url}: {e}\")\n",
    "\n",
    "try:\n",
    "    base_url = 'https://www.molteni.it/ap/kitchens/category/highlights'\n",
    "    product_links = get_product_links(base_url)\n",
    "    for link in product_links:\n",
    "        scrape_product_page(link)\n",
    "\n",
    "except (NoSuchElementException, TimeoutException) as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "# Path to your WebDriver executable\n",
    "webdriver_path = 'D:/Internship_Developers_den/web_scraping/folder_driver/chromedriver-win64/chromedriver.exe'\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Uncomment if you want to run it headlessly\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(webdriver_path), options=chrome_options)\n",
    "\n",
    "def download_image(image_url, folder_path, image_name):\n",
    "    try:\n",
    "        response = requests.get(image_url, stream=True)\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        with open(image_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                file.write(chunk)\n",
    "        print(f\"Saved image: {image_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {image_url}. Reason: {e}\")\n",
    "\n",
    "def download_file(file_url, folder_path, file_name):\n",
    "    try:\n",
    "        response = requests.get(file_url, stream=True)\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                file.write(chunk)\n",
    "        print(f\"Saved file: {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {file_url}. Reason: {e}\")\n",
    "\n",
    "def extract_images_from_selector(selector, folder_path, image_counter):\n",
    "    try:\n",
    "        container_divs = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, selector))\n",
    "        )\n",
    "        for container_div in container_divs:\n",
    "            all_images = container_div.find_elements(By.TAG_NAME, \"img\")\n",
    "            for img in all_images:\n",
    "                image_src = img.get_attribute('src')\n",
    "                image_name = f\"image_{image_counter}.png\"\n",
    "                download_image(image_src, folder_path, image_name)\n",
    "                image_counter += 1\n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(f\"No images found inside the container {selector} or timeout occurred.\")\n",
    "    return image_counter\n",
    "\n",
    "def get_product_links(base_url):\n",
    "    driver.get(base_url)\n",
    "    links = []\n",
    "    try:\n",
    "        product_elements = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section.product-category > div > div > div > section.content-block.catalog-list > article > a'))\n",
    "        )\n",
    "        for element in product_elements:\n",
    "            link = element.get_attribute('href')\n",
    "            if link:\n",
    "                links.append(link)\n",
    "    except (NoSuchElementException, TimeoutException) as e:\n",
    "        print(f\"An error occurred while fetching product links: {e}\")\n",
    "    return links\n",
    "\n",
    "def scrape_product_page(product_url):\n",
    "    driver.get(product_url)\n",
    "    try:\n",
    "        text_selector = \"body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section:nth-child(1) > div > article > div.block-text-img-text.animation-fade-in > div > div > div.block-info-product__top.padding-line-element\"\n",
    "        try:\n",
    "            info_div = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, text_selector))\n",
    "            )\n",
    "            a_tag = info_div.find_element(By.TAG_NAME, \"a\")\n",
    "            h1_tag = a_tag.find_element(By.TAG_NAME, \"h1\")\n",
    "            h1_text = h1_tag.text.strip()\n",
    "            print(\"H1 Text:\", h1_text)\n",
    "            folder_path = os.path.join(os.getcwd(), h1_text.replace('/', '_').replace('\\\\', '_'))\n",
    "            os.makedirs(folder_path, exist_ok=True)\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            print(\"H1 tag not found inside the specified container or timeout occurred.\")\n",
    "            folder_path = os.getcwd()\n",
    "\n",
    "        selectors = [\n",
    "            \"body > div.wrapper-site.avgrund-contents.no-ecommerce-bar > section:nth-child(1)\",\n",
    "            \"#block-0\",\n",
    "            \"#block-1\",\n",
    "            \"#block-2\",\n",
    "            \"#block-3\",\n",
    "            \"#block-4\",\n",
    "            \"#block-5\",\n",
    "            \"#block-6\",\n",
    "            \"#block-7\",\n",
    "            \"#block-8\",\n",
    "            \"#block-9\",\n",
    "            \"#block-10\",\n",
    "            \"#block-11\"\n",
    "        ]\n",
    "        image_counter = 1\n",
    "        for selector in selectors:\n",
    "            image_counter = extract_images_from_selector(selector, folder_path, image_counter)\n",
    "\n",
    "        anchor_selector = \"#specs > div > div.row.product-specs-row > div:nth-child(3) > a\"\n",
    "        try:\n",
    "            anchor_tag = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, anchor_selector))\n",
    "            )\n",
    "            file_url = anchor_tag.get_attribute('href')\n",
    "            file_name = \"description.pdf\"\n",
    "            download_file(file_url, folder_path, file_name)\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            print(\"Anchor tag not found inside the specified container or timeout occurred.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the product page {product_url}: {e}\")\n",
    "\n",
    "try:\n",
    "    base_url = 'https://www.molteni.it/ap/gio-ponti/category/highlights'\n",
    "    product_links = get_product_links(base_url)\n",
    "    for link in product_links:\n",
    "        scrape_product_page(link)\n",
    "\n",
    "except (NoSuchElementException, TimeoutException) as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "# Path to your WebDriver executable\n",
    "webdriver_path = 'D:/Internship_Developers_den/web_scraping/folder_driver/chromedriver-win64/chromedriver.exe'\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Uncomment if you want to run it headlessly\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(webdriver_path), options=chrome_options)\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    # Remove any characters that are invalid in Windows file names and trim whitespace\n",
    "    filename = re.sub(r'[<>:\"/\\\\|?*\\n\\r]', '', filename).strip()\n",
    "    return filename\n",
    "\n",
    "def download_image(image_url, folder_path, image_name):\n",
    "    try:\n",
    "        response = requests.get(image_url, stream=True)\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        with open(image_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                file.write(chunk)\n",
    "        print(f\"Saved image: {image_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {image_url}. Reason: {e}\")\n",
    "\n",
    "def download_file(file_url, folder_path, file_name):\n",
    "    try:\n",
    "        response = requests.get(file_url, stream=True)\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                file.write(chunk)\n",
    "        print(f\"Saved file: {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {file_url}. Reason: {e}\")\n",
    "\n",
    "def extract_images_from_selector(selector, folder_path, image_counter):\n",
    "    try:\n",
    "        container_divs = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, selector))\n",
    "        )\n",
    "        for container_div in container_divs:\n",
    "            all_images = container_div.find_elements(By.TAG_NAME, \"img\")\n",
    "            for img in all_images:\n",
    "                image_src = img.get_attribute('src')\n",
    "                if image_src:\n",
    "                    image_name = f\"image_{image_counter}.png\"\n",
    "                    download_image(image_src, folder_path, image_name)\n",
    "                    image_counter += 1\n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(f\"No images found inside the container {selector} or timeout occurred.\")\n",
    "    return image_counter\n",
    "\n",
    "def get_product_links(base_url):\n",
    "    driver.get(base_url)\n",
    "    links = []\n",
    "    try:\n",
    "        # Use the provided selector to locate the container with multiple tags\n",
    "        container_selector = \"#c25957 > div > section.container.prv-list.show-sofa-1\"\n",
    "        \n",
    "        # Wait for the container to be present and extract anchor elements from it\n",
    "        container = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, container_selector))\n",
    "        )\n",
    "        \n",
    "        # Find all <a> tags within the container\n",
    "        product_elements = container.find_elements(By.TAG_NAME, 'a')\n",
    "        \n",
    "        # Extract the URLs from the href attributes of each <a> tag\n",
    "        for element in product_elements:\n",
    "            link = element.get_attribute('href')\n",
    "            if link:\n",
    "                links.append(link)\n",
    "                print(f\"Product link found: {link}\")\n",
    "    except (NoSuchElementException, TimeoutException) as e:\n",
    "        print(f\"An error occurred while fetching product links: {e}\")\n",
    "    return links\n",
    "\n",
    "def scrape_product_page(product_url):\n",
    "    driver.get(product_url)\n",
    "    try:\n",
    "            \n",
    "        # Use the new H1 selector for folder naming\n",
    "        h1_selector = \"#c205373 > div > section > div > div > h1\"\n",
    "        try:\n",
    "            h1_element = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, h1_selector))\n",
    "            )\n",
    "            h1_text = h1_element.text.strip()\n",
    "            print(\"H1 Text (Folder Name):\", h1_text)\n",
    "            folder_name = sanitize_filename(h1_text)\n",
    "            folder_path = os.path.join(os.getcwd(), folder_name)\n",
    "            os.makedirs(folder_path, exist_ok=True)\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            print(\"H1 tag not found or timeout occurred.\")\n",
    "            folder_path = os.getcwd()  # Default to current directory\n",
    "\n",
    "        # New selectors for images\n",
    "        selectors = [\n",
    "            \"#c206647\",  # First container with multiple tags with images\n",
    "            \"body > main > section:nth-child(8)\",  # Second container with multiple divs containing images\n",
    "            \"body > main > section:nth-child(9)\"   # Third container with multiple divs containing images\n",
    "        ]\n",
    "        \n",
    "        # Extract images from new selectors\n",
    "        image_counter = 1\n",
    "        for selector in selectors:\n",
    "            image_counter = extract_images_from_selector(selector, folder_path, image_counter)\n",
    "\n",
    "        # New selector for file download\n",
    "        file_selector = \"#c205373 > div > section > div > div > ul:nth-child(4) > li:nth-child(2) > a\"\n",
    "        try:\n",
    "            anchor_tag = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, file_selector))\n",
    "            )\n",
    "            file_url = anchor_tag.get_attribute('href')\n",
    "            file_name = \"description.pdf\"\n",
    "            download_file(file_url, folder_path, file_name)\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            print(\"File download link not found or timeout occurred.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the product page {product_url}: {e}\")\n",
    "\n",
    "try:\n",
    "    base_url = 'https://www.rolf-benz.com/en_OC/furniture/sofas'\n",
    "    product_links = get_product_links(base_url)\n",
    "    print(f\"Total product links found: {len(product_links)}\")\n",
    "    \n",
    "    # Visit each product page and scrape the required data\n",
    "    for link in product_links:\n",
    "        scrape_product_page(link)\n",
    "\n",
    "except (NoSuchElementException, TimeoutException) as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "# Path to your WebDriver executable\n",
    "webdriver_path = 'D:/Internship_Developers_den/web_scraping/folder_driver/chromedriver-win64/chromedriver.exe'\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Uncomment if you want to run it headlessly\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(webdriver_path), options=chrome_options)\n",
    "\n",
    "def get_product_links(base_url):\n",
    "    driver.get(base_url)\n",
    "    links = []\n",
    "    try:\n",
    "        # Use the provided selector to locate the container with multiple tags\n",
    "        container_selector = \"#c25957 > div > section.container.prv-list.show-sofa-1\"\n",
    "        \n",
    "        # Wait for the container to be present and extract anchor elements from it\n",
    "        container = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, container_selector))\n",
    "        )\n",
    "        \n",
    "        # Find all <a> tags within the container\n",
    "        product_elements = container.find_elements(By.TAG_NAME, 'a')\n",
    "        \n",
    "        # Extract the URLs from the href attributes of each <a> tag\n",
    "        for element in product_elements:\n",
    "            link = element.get_attribute('href')\n",
    "            if link:\n",
    "                links.append(link)\n",
    "                print(f\"Product link found: {link}\")\n",
    "    except (NoSuchElementException, TimeoutException) as e:\n",
    "        print(f\"An error occurred while fetching product links: {e}\")\n",
    "    return links\n",
    "\n",
    "def download_file(file_url, folder_path, file_name):\n",
    "    try:\n",
    "        response = requests.get(file_url, stream=True)\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                file.write(chunk)\n",
    "        print(f\"Saved file: {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {file_url}. Reason: {e}\")\n",
    "\n",
    "def extract_and_save_product_info(url):\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        # Extract text after \"sofas/\"\n",
    "        if \"sofas/\" in url:\n",
    "            text_after_sofas = url.split(\"sofas/\")[1]\n",
    "            # Add \"rolf-benz\" if not present\n",
    "            if \"rolf-benz\" not in text_after_sofas:\n",
    "                text_after_sofas = f\"rolf-benz {text_after_sofas}\"\n",
    "            print(f\"Extracted text: {text_after_sofas}\")\n",
    "            \n",
    "            # Create a folder with the extracted text\n",
    "            folder_name = text_after_sofas.replace('/', '_').replace('\\\\', '_')\n",
    "            folder_path = os.path.join(os.getcwd(), folder_name)\n",
    "            os.makedirs(folder_path, exist_ok=True)\n",
    "            \n",
    "            # List of XPaths to try for downloading the file\n",
    "            file_xpaths = [\n",
    "                \"/html/body/main/div[9]/section/div/div/ul/li[1]/a\",\n",
    "                \"/html/body/main/div[5]/div/section/div/div/ul[1]/li[2]/a\",\n",
    "                \"/html/body/main/div[2]/div/section/div/div/ul[1]/li[1]/a\",\n",
    "                \"/html/body/main/div[2]/div/section/div/div/ul[1]/li[2]/a\",\n",
    "                \"/html/body/main/div[8]/section/div/div/ul/li[1]/a\",\n",
    "                \"/html/body/main/div[2]/div/section/div/div/ul[1]/li[1]/a\",\n",
    "                \"/html/body/main/div[8]/section/div/div/ul/li/a\",\n",
    "                \"/html/body/main/div[6]/div/section/div/div/ul[1]/li[2]/a\",\n",
    "                \"/html/body/main/div[2]/div/section/div/div/ul[1]/li/a\",\n",
    "                \"/html/body/main/div[8]/section/div/div/ul/li[1]/a\"\n",
    "            ]\n",
    "            \n",
    "            file_url = None\n",
    "            for xpath in file_xpaths:\n",
    "                try:\n",
    "                    file_element = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.XPATH, xpath))\n",
    "                    )\n",
    "                    file_url = file_element.get_attribute('href')\n",
    "                    if file_url:\n",
    "                        break\n",
    "                except (NoSuchElementException, TimeoutException):\n",
    "                    continue\n",
    "            \n",
    "            if file_url:\n",
    "                download_file(file_url, folder_path, 'description.pdf')\n",
    "            else:\n",
    "                print(\"File not found using any provided XPaths.\")\n",
    "                \n",
    "        else:\n",
    "            print(\"URL does not contain 'sofas/'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the URL {url}: {e}\")\n",
    "\n",
    "try:\n",
    "    base_url = 'https://www.rolf-benz.com/en_OC/furniture/sofas'\n",
    "    product_links = get_product_links(base_url)\n",
    "    print(f\"Total product links found: {len(product_links)}\")\n",
    "    \n",
    "    # Visit each product page and process the information\n",
    "    for link in product_links:\n",
    "        extract_and_save_product_info(link)\n",
    "\n",
    "except (NoSuchElementException, TimeoutException) as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "# Path to your WebDriver executable\n",
    "webdriver_path = 'D:/Internship_Developers_den/web_scraping/folder_driver/chromedriver-win64/chromedriver.exe'\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Uncomment if you want to run it headlessly\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(webdriver_path), options=chrome_options)\n",
    "\n",
    "def get_product_links(base_url):\n",
    "    driver.get(base_url)\n",
    "    links = []\n",
    "    try:\n",
    "        # Use the updated XPath to find the container\n",
    "        container_xpath = \"/html/body/main/div/div/section[2]/div\"\n",
    "        container = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, container_xpath))\n",
    "        )\n",
    "        \n",
    "        # Find all <a> tags within the container\n",
    "        product_elements = container.find_elements(By.TAG_NAME, 'a')\n",
    "        for element in product_elements:\n",
    "            link = element.get_attribute('href')\n",
    "            if link and link.startswith(\"http\"):  # Ensure it's a valid URL\n",
    "                links.append(link)\n",
    "                print(f\"Product link found: {link}\")\n",
    "    except (NoSuchElementException, TimeoutException) as e:\n",
    "        print(f\"An error occurred while fetching product links: {e}\")\n",
    "    return links\n",
    "\n",
    "def download_image(image_url, folder_path, image_counter):\n",
    "    try:\n",
    "        response = requests.get(image_url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Open the image using Pillow\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        \n",
    "        # Convert the image to PNG format\n",
    "        image = image.convert(\"RGBA\")\n",
    "        \n",
    "        image_name = f\"image_{image_counter}.png\"\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        \n",
    "        # Save the image in PNG format\n",
    "        image.save(image_path, format=\"PNG\")\n",
    "        print(f\"Saved image: {image_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {image_url}. Reason: {e}\")\n",
    "\n",
    "def extract_images_from_div(div_element, folder_path, image_counter):\n",
    "    try:\n",
    "        images = div_element.find_elements(By.TAG_NAME, \"img\")\n",
    "        for img in images:\n",
    "            image_src = img.get_attribute('src')\n",
    "            if image_src:\n",
    "                download_image(image_src, folder_path, image_counter)\n",
    "                image_counter += 1\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while extracting images: {e}\")\n",
    "    return image_counter\n",
    "\n",
    "def download_file(file_url, folder_path, file_name):\n",
    "    try:\n",
    "        response = requests.get(file_url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Save the file to the specified folder\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                file.write(chunk)\n",
    "        print(f\"Saved file: {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {file_url}. Reason: {e}\")\n",
    "\n",
    "def extract_files_from_page(folder_path):\n",
    "    file_xpaths = [\n",
    "        \"/html/body/main/div[2]/div/section/div/div/ul[1]/li/a\",\n",
    "        \"/html/body/main/div[2]/div/section/div/div/ul[1]/li[1]/a\"\n",
    "    ]\n",
    "    \n",
    "    for file_xpath in file_xpaths:\n",
    "        try:\n",
    "            file_element = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, file_xpath))\n",
    "            )\n",
    "            file_url = file_element.get_attribute('href')\n",
    "            if file_url and file_url.endswith(\".pdf\"):\n",
    "                file_name = \"description.pdf\"\n",
    "                download_file(file_url, folder_path, file_name)\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            continue\n",
    "\n",
    "def extract_and_save_product_info(url):\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        # If \"beds/\" is in the URL, extract the text after it\n",
    "        if \"beds/\" in url:\n",
    "            text_after_beds = url.split(\"beds/\")[1]\n",
    "        else:\n",
    "            # If \"beds/\" is not in the URL, use the whole URL and ensure the folder contains \"beds\"\n",
    "            text_after_beds = url.split('/')[-1]\n",
    "            text_after_beds = f\"beds_{text_after_beds}\"\n",
    "        \n",
    "        if \"rolf-benz\" not in text_after_beds:\n",
    "            text_after_beds = f\"rolf-benz {text_after_beds}\"\n",
    "        print(f\"Extracted text: {text_after_beds}\")\n",
    "        \n",
    "        # Create the folder name by sanitizing the extracted text\n",
    "        folder_name = text_after_beds.replace('/', '_').replace('\\\\', '_')\n",
    "        folder_path = os.path.join(os.getcwd(), folder_name)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        \n",
    "        # List of XPaths to try for downloading images\n",
    "        div_xpaths = [\n",
    "            \"/html/body/main/div[1]/section/div/div\",\n",
    "            \"/html/body/main/div[5]/section/div/div/div/div\",\n",
    "            \"/html/body/main/div[6]/section/div/div/div/div\",\n",
    "            \"/html/body/main/section[1]\",\n",
    "            \"/html/body/main/section[2]\",\n",
    "            \"/html/body/main/div[1]/section/div/div/div/div[1]\",\n",
    "            \"/html/body/main/div[3]/section\",\n",
    "            \"/html/body/main/div[3]/section/div/div/div/div[1]\",\n",
    "            \"/html/body/main/section[1]/div/div[1]/div/div/div\",\n",
    "            \"/html/body/main/div[5]/section/div/div/div/div\",\n",
    "            \"/html/body/main/div[6]\",\n",
    "            \"/html/body/main/div[5]/section/div/div/div/div[1]\"\n",
    "        ]\n",
    "        \n",
    "        image_counter = 1\n",
    "        for xpath in div_xpaths:\n",
    "            try:\n",
    "                div_element = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, xpath))\n",
    "                )\n",
    "                image_counter = extract_images_from_div(div_element, folder_path, image_counter)\n",
    "            except (NoSuchElementException, TimeoutException):\n",
    "                continue\n",
    "\n",
    "        # Download files (PDFs)\n",
    "        extract_files_from_page(folder_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the URL {url}: {e}\")\n",
    "\n",
    "try:\n",
    "    base_url = 'https://www.rolf-benz.com/en_OC/furniture/beds'\n",
    "    product_links = get_product_links(base_url)\n",
    "    print(f\"Total product links found: {len(product_links)}\")\n",
    "    \n",
    "    for link in product_links:\n",
    "        extract_and_save_product_info(link)\n",
    "\n",
    "except (NoSuchElementException, TimeoutException) as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# Path to your WebDriver executable\n",
    "webdriver_path = 'D:/Internship_Developers_den/web_scraping/folder_driver/chromedriver-win64/chromedriver.exe'\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Uncomment if you want to run it headlessly\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(webdriver_path), options=chrome_options)\n",
    "\n",
    "def download_image(image_url, folder_path, image_counter, base_url):\n",
    "    try:\n",
    "        # Convert relative URLs to absolute URLs\n",
    "        if not image_url.startswith(\"http\"):\n",
    "            image_url = urljoin(base_url, image_url)\n",
    "\n",
    "        response = requests.get(image_url, stream=True)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Open the image using Pillow\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "\n",
    "        # Convert the image to PNG format\n",
    "        image = image.convert(\"RGBA\")\n",
    "\n",
    "        image_name = f\"image_{image_counter}.png\"\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "\n",
    "        # Save the image in PNG format\n",
    "        image.save(image_path, format=\"PNG\")\n",
    "        print(f\"Saved image: {image_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {image_url}. Reason: {e}\")\n",
    "\n",
    "def download_pdf(pdf_url, folder_path):\n",
    "    try:\n",
    "        # Convert relative URLs to absolute URLs\n",
    "        if not pdf_url.startswith(\"http\"):\n",
    "            pdf_url = urljoin(url, pdf_url)\n",
    "\n",
    "        response = requests.get(pdf_url, stream=True)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        pdf_path = os.path.join(folder_path, \"description.pdf\")\n",
    "        with open(pdf_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        print(f\"Saved PDF: description.pdf\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download PDF {pdf_url}. Reason: {e}\")\n",
    "\n",
    "def extract_images_from_main(main_element, folder_path, image_counter, base_url):\n",
    "    try:\n",
    "        # Find all <img> tags within the main element\n",
    "        images = main_element.find_elements(By.TAG_NAME, \"img\")\n",
    "        for img in images:\n",
    "            # Check both 'src' and 'data-src' for lazy-loaded images\n",
    "            image_src = img.get_attribute('src') or img.get_attribute('data-src')\n",
    "            if image_src:\n",
    "                print(f\"Trying to download image: {image_src}\")\n",
    "                download_image(image_src, folder_path, image_counter, base_url)\n",
    "                image_counter += 1\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while extracting images: {e}\")\n",
    "    return image_counter\n",
    "\n",
    "def extract_and_save_product_info(url):\n",
    "    driver.get(url)\n",
    "\n",
    "    try:\n",
    "        # Define the folder name for this page\n",
    "        folder_name = \"rolf-benz-wardrobe\"\n",
    "        folder_path = os.path.join(os.getcwd(), folder_name)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "        # Find the main element using the CSS selector 'body > main'\n",
    "        main_element = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"body > main\"))\n",
    "        )\n",
    "\n",
    "        image_counter = 1\n",
    "        # Extract all images from within the main tag\n",
    "        image_counter = extract_images_from_main(main_element, folder_path, image_counter, url)\n",
    "\n",
    "        # Find the PDF link and download the PDF\n",
    "        pdf_link = driver.find_element(By.CSS_SELECTOR, \"#c162599 > div > section > div > div > ul:nth-child(3) > li > a\")\n",
    "        pdf_url = pdf_link.get_attribute('href')\n",
    "        if pdf_url:\n",
    "            print(f\"Trying to download PDF: {pdf_url}\")\n",
    "            download_pdf(pdf_url, folder_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the URL {url}: {e}\")\n",
    "\n",
    "try:\n",
    "    # URL for the Rolf Benz Stretto wardrobe furniture page\n",
    "    url = 'https://www.rolf-benz.com/en_OC/furniture/wardrobe-furniture/stretto'\n",
    "    extract_and_save_product_info(url)\n",
    "\n",
    "except (NoSuchElementException, TimeoutException) as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, ElementClickInterceptedException\n",
    "\n",
    "# Path to your WebDriver executable\n",
    "webdriver_path = 'D:/Internship_Developers_den/web_scraping/folder_driver/chromedriver-win64/chromedriver.exe'\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Uncomment if you want to run it headlessly\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(webdriver_path), options=chrome_options)\n",
    "\n",
    "def load_all_images():\n",
    "    try:\n",
    "        # JavaScript path to find the \"Load More\" button\n",
    "        load_images_button_js = \"document.querySelector('#container-6ac6ef4ec3 > div > div.productlist.productcollection.margin-bottom-xxl.aem-GridColumn.aem-GridColumn--default--12 > article > button')\"\n",
    "        \n",
    "        # Wait for the page to fully load before interacting\n",
    "        print(\"Waiting for the page to load for 15 seconds...\")\n",
    "        time.sleep(15)\n",
    "\n",
    "        # Track if the \"Load More\" button is visible\n",
    "        button_visible = True\n",
    "        \n",
    "        while button_visible:\n",
    "            try:\n",
    "                # Execute JavaScript to find the \"Load More\" button\n",
    "                button = driver.execute_script(f\"return {load_images_button_js};\")\n",
    "                \n",
    "                if button and button.is_displayed():\n",
    "                    driver.execute_script(\"arguments[0].click();\", button)\n",
    "                    print(\"Clicked 'Load More' button.\")\n",
    "                    \n",
    "                    # Wait for a short period before checking again to avoid immediate page reload\n",
    "                    time.sleep(10)\n",
    "                    \n",
    "                    # Wait for new images to load\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.staleness_of(button)  # Wait until the button is no longer clickable\n",
    "                    )\n",
    "                else:\n",
    "                    button_visible = False\n",
    "            except (NoSuchElementException, TimeoutException, ElementClickInterceptedException) as e:\n",
    "                print(f\"No more 'Load More' button or unable to click. Error: {e}\")\n",
    "                button_visible = False\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading all images: {e}\")\n",
    "\n",
    "def get_product_name():\n",
    "    \"\"\"Get the name of the product from the current page.\"\"\"\n",
    "    try:\n",
    "        # XPath to find the product name\n",
    "        name_xpath = \"/html/body/div[1]/div/main/div/div/div/div/div/div[2]/article/section/div[3]/div[1]/div/a/div[2]\"\n",
    "        \n",
    "        # Wait for the name element to appear on the product page\n",
    "        name_element = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, name_xpath))\n",
    "        )\n",
    "        product_name = name_element.text.strip()\n",
    "        print(f\"Product name: {product_name}\")\n",
    "        return product_name\n",
    "\n",
    "    except (NoSuchElementException, TimeoutException) as e:\n",
    "        print(f\"Error fetching product name: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_product_links(base_url):\n",
    "    \"\"\"Fetch product links and immediately process each link.\"\"\"\n",
    "    driver.get(base_url)\n",
    "\n",
    "    # Wait for the page to fully load before extracting product links\n",
    "    print(\"Waiting for the page to load for 15 seconds...\")\n",
    "    time.sleep(15)\n",
    "\n",
    "    links = []\n",
    "    try:\n",
    "        # CSS selector to find the container with product links\n",
    "        container_selector = \"#container-6ac6ef4ec3 > div > div.productlist.productcollection.margin-bottom-xxl.aem-GridColumn.aem-GridColumn--default--12 > article > section > div.gallery__items.search__items\"\n",
    "        load_more_button_js = \"document.querySelector('#container-6ac6ef4ec3 > div > div.productlist.productcollection.margin-bottom-xxl.aem-GridColumn.aem-GridColumn--default--12 > article > button')\"\n",
    "\n",
    "        while True:\n",
    "            # Wait for the container to be present\n",
    "            container = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, container_selector))\n",
    "            )\n",
    "            \n",
    "            # Find all <a> tags within the container\n",
    "            product_elements = container.find_elements(By.TAG_NAME, 'a')\n",
    "            for element in product_elements:\n",
    "                link = element.get_attribute('href')\n",
    "                if link and link.startswith(\"http\"):  # Ensure it's a valid URL\n",
    "                    if link not in links:\n",
    "                        links.append(link)\n",
    "                        print(f\"Product link found: {link}\")\n",
    "                        \n",
    "                        # Visit the product link to fetch the product name and create folder\n",
    "                        visit_product_link_and_create_folder(link)\n",
    "                        \n",
    "            try:\n",
    "                # Execute JavaScript to find and click the \"Load More\" button\n",
    "                load_more_button = driver.execute_script(f\"return {load_more_button_js};\")\n",
    "                if load_more_button and load_more_button.is_displayed():\n",
    "                    driver.execute_script(\"arguments[0].click();\", load_more_button)\n",
    "                    print(\"Clicked 'Load More' button.\")\n",
    "                    \n",
    "                    # Wait for new products to load\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.staleness_of(load_more_button)  # Wait until the button is no longer clickable\n",
    "                    )\n",
    "                else:\n",
    "                    break\n",
    "            except (NoSuchElementException, TimeoutException) as e:\n",
    "                print(f\"No more 'Load More' button or unable to click. Error: {e}\")\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fetching product links: {e}\")\n",
    "    \n",
    "    return links\n",
    "\n",
    "def visit_product_link_and_create_folder(link):\n",
    "    \"\"\"Visit each product link, get the name, and create a folder for it.\"\"\"\n",
    "    try:\n",
    "        driver.get(link)\n",
    "        print(f\"Visited product link: {link}\")\n",
    "        \n",
    "        # Wait for the page to fully load\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Get the product name from the product page\n",
    "        product_name = get_product_name()\n",
    "        if product_name:\n",
    "            # Sanitize product name to be a valid folder name\n",
    "            sanitized_name = \"\".join(c for c in product_name if c.isalnum() or c in (\" \", \"_\")).strip()\n",
    "            product_folder = os.path.join(os.getcwd(), sanitized_name)\n",
    "            os.makedirs(product_folder, exist_ok=True)\n",
    "\n",
    "            print(f\"Created folder '{product_folder}' for product '{product_name}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while visiting {link}: {e}\")\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    base_url = 'https://www.poltronafrau.com/ww/en/products/products.87.html?category_id=87&selectedFilters=pf_info_categoria&pf_info_categoria=9088'\n",
    "    \n",
    "    # Load all images by clicking the 'Load All Images' button\n",
    "    load_all_images()\n",
    "\n",
    "    # Fetch product links, visit each product link, and create folders\n",
    "    product_links = get_product_links(base_url)\n",
    "    print(f\"Total product links found and processed: {len(product_links)}\")\n",
    "\n",
    "except (NoSuchElementException, TimeoutException) as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# Path to your WebDriver executable\n",
    "webdriver_path = 'D:/Internship_Developers_den/web_scraping/folder_driver/chromedriver-win64/chromedriver.exe'\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Uncomment if you want to run it headlessly\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(webdriver_path), options=chrome_options)\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    \"\"\" Remove or replace invalid characters from filenames/folders \"\"\"\n",
    "    invalid_chars = '<>:\"/\\\\|?*'\n",
    "    for char in invalid_chars:\n",
    "        filename = filename.replace(char, '_')\n",
    "    return filename\n",
    "\n",
    "def download_image(image_url, folder_name, idx):\n",
    "    try:\n",
    "        # Ensure the image URL is absolute\n",
    "        if not image_url.startswith(\"http\"):\n",
    "            image_url = \"https://www.poltronafrau.com\" + image_url\n",
    "\n",
    "        # Create the download folder using the sanitized folder name\n",
    "        download_folder = os.path.join(os.getcwd(), folder_name)\n",
    "        os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "        # Download the image\n",
    "        response = requests.get(image_url)\n",
    "        if response.status_code == 200:\n",
    "            image_path = os.path.join(download_folder, f'image_{idx + 1}.png')\n",
    "            with open(image_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Downloaded image {idx + 1} in folder '{folder_name}' from URL: {image_url}\")\n",
    "        else:\n",
    "            print(f\"Failed to download image {idx + 1}, status code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image {idx + 1}: {e}\")\n",
    "\n",
    "def download_images_from_product_page(folder_name):\n",
    "    try:\n",
    "        # Locate the image elements with the srcset attribute\n",
    "        img_selector = \"img.cmp-image__image\"\n",
    "        image_elements = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, img_selector))\n",
    "        )\n",
    "\n",
    "        for idx, img_element in enumerate(image_elements):\n",
    "            # Extract the srcset attribute (which contains URLs for different image resolutions)\n",
    "            srcset = img_element.get_attribute('srcset')\n",
    "            if not srcset:\n",
    "                # Fallback to data-srcset if srcset is not present\n",
    "                srcset = img_element.get_attribute('data-srcset')\n",
    "\n",
    "            if srcset:\n",
    "                # Split the srcset string into individual image URLs and resolutions\n",
    "                srcset_items = [item.strip() for item in srcset.split(\",\")]\n",
    "\n",
    "                # Extract the highest resolution image (assuming it's the last in the srcset)\n",
    "                highest_res_image = srcset_items[-1].split()[0]\n",
    "                print(f\"Highest resolution image URL: {highest_res_image}\")\n",
    "\n",
    "                # Download the highest-resolution image\n",
    "                download_image(highest_res_image, folder_name, idx)\n",
    "            else:\n",
    "                # If no srcset is found, attempt to download the standard src image\n",
    "                src = img_element.get_attribute('src')\n",
    "                if src:\n",
    "                    print(f\"Falling back to src image: {src}\")\n",
    "                    download_image(src, folder_name, idx)\n",
    "                else:\n",
    "                    print(f\"No src or srcset found for image {idx + 1}\")\n",
    "\n",
    "    except TimeoutException as e:\n",
    "        print(f\"Error locating images: {e}\")\n",
    "\n",
    "def get_folder_name_from_url(product_url):\n",
    "    \"\"\"Extract folder name from the product URL\"\"\"\n",
    "    try:\n",
    "        # Extract the folder name from the URL after 'products/' and before '.html'\n",
    "        part_after_products = product_url.split('products/')[1]\n",
    "        folder_name = part_after_products.split('.html')[0]\n",
    "        return sanitize_filename(folder_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting folder name: {e}\")\n",
    "        return \"default_folder\"\n",
    "\n",
    "def visit_product_page_and_download_images(product_url):\n",
    "    try:\n",
    "        print(f\"Visiting product page: {product_url}\")\n",
    "        driver.get(product_url)\n",
    "\n",
    "        # Wait for the page to load\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Get the folder name based on the product URL\n",
    "        folder_name = get_folder_name_from_url(product_url)\n",
    "\n",
    "        # Download images from the product page\n",
    "        download_images_from_product_page(folder_name)\n",
    "\n",
    "        # After downloading images, click on the \"Downloads\" tab\n",
    "        click_download_tab()\n",
    "\n",
    "        # After clicking the download tab, download the ZIP file and extract its contents\n",
    "        download_and_extract_zip_file(folder_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error visiting product page {product_url}: {e}\")\n",
    "\n",
    "def click_download_tab():\n",
    "    \"\"\"Clicks the 'Downloads' tab based on the provided selector\"\"\"\n",
    "    try:\n",
    "        # Wait for the tab element to be clickable and then click it\n",
    "        tab_selector = \"#producttabs-3baf65de06-item-25a16ecc4d-tab\"\n",
    "        download_tab = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, tab_selector))\n",
    "        )\n",
    "        download_tab.click()\n",
    "        print(\"Successfully clicked the 'Downloads' tab.\")\n",
    "        \n",
    "    except TimeoutException as e:\n",
    "        print(f\"Error clicking the 'Downloads' tab: {e}\")\n",
    "\n",
    "def download_and_extract_zip_file(folder_name):\n",
    "    \"\"\"Download the ZIP file from the newly appeared <a> tag and extract it into the same folder\"\"\"\n",
    "    try:\n",
    "        # Wait for the <a> tag to become visible\n",
    "        a_tag_selector = \"#professionals > div > div > div:nth-child(1) > div > h3 > button > a\"\n",
    "        a_tag_element = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, a_tag_selector))\n",
    "        )\n",
    "\n",
    "        # Get the URL from the href attribute\n",
    "        file_url = a_tag_element.get_attribute('href')\n",
    "        if file_url:\n",
    "            print(f\"Found ZIP file download URL: {file_url}\")\n",
    "\n",
    "            # Create a downloads folder if it doesn't exist\n",
    "            download_folder = os.path.join(os.getcwd(), folder_name)\n",
    "            os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "            # Download the ZIP file with headers and cookies\n",
    "            headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36',\n",
    "                'Referer': driver.current_url,\n",
    "            }\n",
    "            # Extract cookies from the Selenium session\n",
    "            cookies = {cookie['name']: cookie['value'] for cookie in driver.get_cookies()}\n",
    "\n",
    "            # Download the ZIP file\n",
    "            response = requests.get(file_url, headers=headers, cookies=cookies)\n",
    "            if response.status_code == 200:\n",
    "                # Extract the ZIP file in-memory\n",
    "                with zipfile.ZipFile(BytesIO(response.content)) as zip_file:\n",
    "                    # Extract all contents to the download folder\n",
    "                    zip_file.extractall(download_folder)\n",
    "                    print(f\"Extracted ZIP contents to folder '{folder_name}'\")\n",
    "\n",
    "                    # Process the PDF file inside the ZIP file\n",
    "                    for file_name in zip_file.namelist():\n",
    "                        if file_name.endswith('.pdf'):\n",
    "                            pdf_path = os.path.join(download_folder, file_name)\n",
    "                            print(f\"Found PDF file: {pdf_path}\")\n",
    "                            # Process the PDF file as needed (e.g., move, read, etc.)\n",
    "            else:\n",
    "                print(f\"Failed to download ZIP file, status code: {response.status_code}\")\n",
    "        else:\n",
    "            print(\"No href found for the download link.\")\n",
    "        \n",
    "    except TimeoutException as e:\n",
    "        print(f\"Error locating the download link: {e}\")\n",
    "\n",
    "def extract_product_links(list_page_url):\n",
    "    try:\n",
    "        print(f\"Visiting list page: {list_page_url}\")\n",
    "        driver.get(list_page_url)\n",
    "\n",
    "        # Click the 'Load More' button if present to load all products\n",
    "        while True:\n",
    "            try:\n",
    "                load_more_button_selector = \"#container-6ac6ef4ec3 > div > div.productlist.productcollection.margin-bottom-xxl.aem-GridColumn.aem-GridColumn--default--12 > article > button\"\n",
    "                load_more_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, load_more_button_selector))\n",
    "                )\n",
    "                load_more_button.click()\n",
    "                print(\"Clicked 'Load More' button.\")\n",
    "                time.sleep(3)  # Wait for new products to load\n",
    "            except TimeoutException:\n",
    "                break\n",
    "\n",
    "        # Extract product links\n",
    "        product_selector = \"#container-6ac6ef4ec3 > div > div.productlist.productcollection.margin-bottom-xxl.aem-GridColumn.aem-GridColumn--default--12 > article > section > div.gallery__items.search__items a\"\n",
    "        product_elements = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, product_selector))\n",
    "        )\n",
    "\n",
    "        product_links = [elem.get_attribute('href') for elem in product_elements if elem.get_attribute('href')]\n",
    "        print(f\"Found {len(product_links)} product links.\")\n",
    "\n",
    "        # Save product links to a file\n",
    "        with open('product_links.txt', 'w') as file:\n",
    "            for link in product_links:\n",
    "                file.write(link + '\\n')\n",
    "\n",
    "        return product_links\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting product links: {e}\")\n",
    "        return []\n",
    "\n",
    "# Main script execution\n",
    "try:\n",
    "    list_page_url = 'https://www.poltronafrau.com/ww/en/products/products.87.html?_gl=1*1fbjz9y*_up*MQ..*_ga*MTY0MDIyNDUyNy4xNzI1OTcyOTc1*_ga_YGJJL14S4G*MTcyNTk3Mjk3NC4xLjEuMTcyNTk3MzA5NC4wLjAuMA..&pf_info_categoria=9103&selectedFilters=pf_info_categoria'\n",
    "    \n",
    "    # Extract and save all product links\n",
    "    product_links = extract_product_links(list_page_url)\n",
    "\n",
    "    # Read the product links from the file and visit each page\n",
    "    with open('product_links.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            product_url = line.strip()\n",
    "            if product_url:\n",
    "                visit_product_page_and_download_images(product_url)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visiting list page: https://www.poltronafrau.com/ww/en/products/products.87.html?_gl=1*7lpixs*_up*MQ..*_ga*MTkwNTg1OTczLjE3MjYwNDI4MDY.*_ga_YGJJL14S4G*MTcyNjA0MjgwNS4xLjAuMTcyNjA0MjgwNS4wLjAuMA..&selectedFilters=pf_info_categoria&pf_info_categoria=11307\n",
      "Found 6 product links.\n",
      "Visiting product page: https://www.poltronafrau.com/ww/en/products/obi-drawer-chest.html\n",
      "Falling back to src image: https://www.poltronafrau.com/content/experience-fragments/poltronafrau/ww/en/site/header/master/_jcr_content/root/header/logoImage.coreimg.65.768.jpeg/1690973285872/logo.jpeg\n",
      "Downloaded image 1 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/content/experience-fragments/poltronafrau/ww/en/site/header/master/_jcr_content/root/header/logoImage.coreimg.65.768.jpeg/1690973285872/logo.jpeg\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/heart2.svg\n",
      "Downloaded image 2 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/heart2.svg\n",
      "No src or srcset found for image 3\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/01_hero/obi-drawer-chest-v1.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 4 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/01_hero/obi-drawer-chest-v1.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "No src or srcset found for image 5\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/02_thumbnails/01_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 6 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/02_thumbnails/01_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/02_thumbnails/02_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 7 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/02_thumbnails/02_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/02_thumbnails/03_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 8 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/02_thumbnails/03_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/02_thumbnails/04_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 9 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/02_thumbnails/04_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/02_thumbnails/05_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 10 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/02_thumbnails/05_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "No src or srcset found for image 11\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/02_thumbnails/02_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 12 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/02_thumbnails/02_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/02_thumbnails/03_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 13 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/02_thumbnails/03_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/02_thumbnails/04_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 14 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/02_thumbnails/04_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/02_thumbnails/05_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 15 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/02_thumbnails/05_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/icon-rotate.svg\n",
      "Downloaded image 16 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/icon-rotate.svg\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/icon-gray-plus.svg\n",
      "Downloaded image 17 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/icon-gray-plus.svg\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/icon-gray-minus.svg\n",
      "Downloaded image 18 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/icon-gray-minus.svg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/03_concept/01_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 19 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/03_concept/01_obi-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Falling back to src image: data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "Error downloading image 20: Failed to parse: https://www.poltronafrau.comdata:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "No src or srcset found for image 21\n",
      "No src or srcset found for image 22\n",
      "No src or srcset found for image 23\n",
      "No src or srcset found for image 24\n",
      "No src or srcset found for image 25\n",
      "No src or srcset found for image 26\n",
      "No src or srcset found for image 27\n",
      "No src or srcset found for image 28\n",
      "No src or srcset found for image 29\n",
      "No src or srcset found for image 30\n",
      "No src or srcset found for image 31\n",
      "No src or srcset found for image 32\n",
      "No src or srcset found for image 33\n",
      "No src or srcset found for image 34\n",
      "No src or srcset found for image 35\n",
      "No src or srcset found for image 36\n",
      "No src or srcset found for image 37\n",
      "No src or srcset found for image 38\n",
      "No src or srcset found for image 39\n",
      "No src or srcset found for image 40\n",
      "No src or srcset found for image 41\n",
      "No src or srcset found for image 42\n",
      "No src or srcset found for image 43\n",
      "No src or srcset found for image 44\n",
      "No src or srcset found for image 45\n",
      "No src or srcset found for image 46\n",
      "No src or srcset found for image 47\n",
      "No src or srcset found for image 48\n",
      "No src or srcset found for image 49\n",
      "No src or srcset found for image 50\n",
      "No src or srcset found for image 51\n",
      "No src or srcset found for image 52\n",
      "No src or srcset found for image 53\n",
      "No src or srcset found for image 54\n",
      "No src or srcset found for image 55\n",
      "No src or srcset found for image 56\n",
      "No src or srcset found for image 57\n",
      "No src or srcset found for image 58\n",
      "No src or srcset found for image 59\n",
      "No src or srcset found for image 60\n",
      "No src or srcset found for image 61\n",
      "No src or srcset found for image 62\n",
      "No src or srcset found for image 63\n",
      "No src or srcset found for image 64\n",
      "No src or srcset found for image 65\n",
      "No src or srcset found for image 66\n",
      "No src or srcset found for image 67\n",
      "No src or srcset found for image 68\n",
      "No src or srcset found for image 69\n",
      "No src or srcset found for image 70\n",
      "No src or srcset found for image 71\n",
      "No src or srcset found for image 72\n",
      "No src or srcset found for image 73\n",
      "No src or srcset found for image 74\n",
      "No src or srcset found for image 75\n",
      "No src or srcset found for image 76\n",
      "No src or srcset found for image 77\n",
      "No src or srcset found for image 78\n",
      "No src or srcset found for image 79\n",
      "No src or srcset found for image 80\n",
      "No src or srcset found for image 81\n",
      "No src or srcset found for image 82\n",
      "No src or srcset found for image 83\n",
      "No src or srcset found for image 84\n",
      "No src or srcset found for image 85\n",
      "No src or srcset found for image 86\n",
      "No src or srcset found for image 87\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 88 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 89\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 90 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 91\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 92 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 93\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 94 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 95\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 96 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 97\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 98 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 99\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 100 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 101\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 102 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 103\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 104 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 105\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 106 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 107\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 108 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 109\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 110 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 111\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 112 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 113\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 114 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 115\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 116 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 117\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 118 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 119\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 120 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 121\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 122 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 123\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 124 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 125\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 126 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 127\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 128 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 129\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 130 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 131\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 132 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 133\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 134 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 135\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 136 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 137\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 138 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 139\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 140 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 141\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 142 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 143\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 144 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 145\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 146 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 147\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 148 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 149\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 150 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 151\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 152 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 153\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 154 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 155\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 156 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 157\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 158 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 159\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 160 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 161\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 162 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 163\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 164 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 165\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 166 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 167\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 168 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 169\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 170 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 171\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 172 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 173\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 174 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 175\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 176 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 177\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 178 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 179\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 180 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 181\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 182 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 183\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 184 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 185\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 186 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 187\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 188 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 189\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 190 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 191\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 192 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 193\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 194 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 195\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 196 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 197\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 198 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 199\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 200 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 201\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 202 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 203\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 204 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 205\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 206 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 207\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 208 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 209\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 210 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 211\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 212 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 213\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 214 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 215\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 216 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 217\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 218 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 219\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 220 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 221\n",
      "No src or srcset found for image 222\n",
      "No src or srcset found for image 223\n",
      "No src or srcset found for image 224\n",
      "No src or srcset found for image 225\n",
      "No src or srcset found for image 226\n",
      "No src or srcset found for image 227\n",
      "No src or srcset found for image 228\n",
      "No src or srcset found for image 229\n",
      "No src or srcset found for image 230\n",
      "No src or srcset found for image 231\n",
      "No src or srcset found for image 232\n",
      "No src or srcset found for image 233\n",
      "No src or srcset found for image 234\n",
      "No src or srcset found for image 235\n",
      "No src or srcset found for image 236\n",
      "No src or srcset found for image 237\n",
      "No src or srcset found for image 238\n",
      "No src or srcset found for image 239\n",
      "No src or srcset found for image 240\n",
      "No src or srcset found for image 241\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 242 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 243\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 244 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 245\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 246 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 247\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 248 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 249\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 250 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 251\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 252 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 253\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 254 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 255\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 256 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 257\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 258 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 259\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 260 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 261\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 262 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 263\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 264 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 265\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 266 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 267\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 268 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 269\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 270 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 271\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 272 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 273\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 274 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 275\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 276 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 277\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 278 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 279\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 280 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 281\n",
      "No src or srcset found for image 282\n",
      "No src or srcset found for image 283\n",
      "No src or srcset found for image 284\n",
      "No src or srcset found for image 285\n",
      "No src or srcset found for image 286\n",
      "No src or srcset found for image 287\n",
      "No src or srcset found for image 288\n",
      "No src or srcset found for image 289\n",
      "No src or srcset found for image 290\n",
      "No src or srcset found for image 291\n",
      "No src or srcset found for image 292\n",
      "No src or srcset found for image 293\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 294 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 295\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 296 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 297\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 298 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 299\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 300 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 301\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 302 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 303\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 304 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 305\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 306 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 307\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 308 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 309\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 310 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 311\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 312 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 313\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 314 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 315\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 316 in folder 'obi-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 317\n",
      "No src or srcset found for image 318\n",
      "No src or srcset found for image 319\n",
      "No src or srcset found for image 320\n",
      "No src or srcset found for image 321\n",
      "No src or srcset found for image 322\n",
      "No src or srcset found for image 323\n",
      "Falling back to src image: data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "Error downloading image 324: Failed to parse: https://www.poltronafrau.comdata:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "Falling back to src image: data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "Error downloading image 325: Failed to parse: https://www.poltronafrau.comdata:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "Falling back to src image: data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "Error downloading image 326: Failed to parse: https://www.poltronafrau.comdata:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "Falling back to src image: data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "Error downloading image 327: Failed to parse: https://www.poltronafrau.comdata:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "Error clicking the 'Downloads' tab: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF69425B5D2+29090]\n",
      "\t(No symbol) [0x00007FF6941CE689]\n",
      "\t(No symbol) [0x00007FF69408B1CA]\n",
      "\t(No symbol) [0x00007FF6940DEFD7]\n",
      "\t(No symbol) [0x00007FF6940DF22C]\n",
      "\t(No symbol) [0x00007FF6941297F7]\n",
      "\t(No symbol) [0x00007FF69410672F]\n",
      "\t(No symbol) [0x00007FF6941265D9]\n",
      "\t(No symbol) [0x00007FF694106493]\n",
      "\t(No symbol) [0x00007FF6940D09B1]\n",
      "\t(No symbol) [0x00007FF6940D1B11]\n",
      "\tGetHandleVerifier [0x00007FF694578C5D+3295277]\n",
      "\tGetHandleVerifier [0x00007FF6945C4843+3605523]\n",
      "\tGetHandleVerifier [0x00007FF6945BA707+3564247]\n",
      "\tGetHandleVerifier [0x00007FF694316EB6+797318]\n",
      "\t(No symbol) [0x00007FF6941D980F]\n",
      "\t(No symbol) [0x00007FF6941D53F4]\n",
      "\t(No symbol) [0x00007FF6941D5580]\n",
      "\t(No symbol) [0x00007FF6941C4A1F]\n",
      "\tBaseThreadInitThunk [0x00007FF882337374+20]\n",
      "\tRtlUserThreadStart [0x00007FF882DBCC91+33]\n",
      "\n",
      "Found ZIP file download URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/20_area_professionals/planning-tools/professionals-obi-drawer-chest_product-sheet.zip\n",
      "Failed to download ZIP file, status code: 403\n",
      "Primary download URL found: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/o/b/i/obi-drawer-chest/20_area_professionals/planning-tools/professionals-obi-drawer-chest_product-sheet.zip\n",
      "Successfully fetched the file.\n",
      "File downloaded and extracted successfully into the folder.\n",
      "Visiting product page: https://www.poltronafrau.com/ww/en/products/fidelio-notte-high-drawer-chest.html\n",
      "Falling back to src image: https://www.poltronafrau.com/content/experience-fragments/poltronafrau/ww/en/site/header/master/_jcr_content/root/header/logoImage.coreimg.65.768.jpeg/1690973285872/logo.jpeg\n",
      "Downloaded image 1 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/content/experience-fragments/poltronafrau/ww/en/site/header/master/_jcr_content/root/header/logoImage.coreimg.65.768.jpeg/1690973285872/logo.jpeg\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/heart2.svg\n",
      "Downloaded image 2 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/heart2.svg\n",
      "No src or srcset found for image 3\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/01_hero/fidelio-notte-high-drawer-chest-v1.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 4 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/01_hero/fidelio-notte-high-drawer-chest-v1.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "No src or srcset found for image 5\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/02_thumbnails/01_fidelio-notte-high-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 6 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/02_thumbnails/01_fidelio-notte-high-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/02_thumbnails/02_fidelio-notte-high-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 7 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/02_thumbnails/02_fidelio-notte-high-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/02_thumbnails/03_fidelio-notte-high-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 8 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/02_thumbnails/03_fidelio-notte-high-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/02_thumbnails/04_fidelio-notte-high-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 9 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/02_thumbnails/04_fidelio-notte-high-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "No src or srcset found for image 10\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/02_thumbnails/02_fidelio-notte-high-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 11 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/02_thumbnails/02_fidelio-notte-high-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/02_thumbnails/03_fidelio-notte-high-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 12 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/02_thumbnails/03_fidelio-notte-high-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/02_thumbnails/04_fidelio-notte-high-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 13 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/02_thumbnails/04_fidelio-notte-high-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/icon-rotate.svg\n",
      "Downloaded image 14 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/icon-rotate.svg\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/icon-gray-plus.svg\n",
      "Downloaded image 15 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/icon-gray-plus.svg\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/icon-gray-minus.svg\n",
      "Downloaded image 16 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/icon-gray-minus.svg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/03_concept/01_notte-high-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 17 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/03_concept/01_notte-high-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Falling back to src image: data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "Error downloading image 18: Failed to parse: https://www.poltronafrau.comdata:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "No src or srcset found for image 19\n",
      "No src or srcset found for image 20\n",
      "No src or srcset found for image 21\n",
      "No src or srcset found for image 22\n",
      "No src or srcset found for image 23\n",
      "No src or srcset found for image 24\n",
      "No src or srcset found for image 25\n",
      "No src or srcset found for image 26\n",
      "No src or srcset found for image 27\n",
      "No src or srcset found for image 28\n",
      "No src or srcset found for image 29\n",
      "No src or srcset found for image 30\n",
      "No src or srcset found for image 31\n",
      "No src or srcset found for image 32\n",
      "No src or srcset found for image 33\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 34 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 35\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 36 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 37\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 38 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 39\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 40 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 41\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 42 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 43\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 44 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 45\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 46 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 47\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 48 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 49\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 50 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 51\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 52 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 53\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 54 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 55\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 56 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 57\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 58 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 59\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 60 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 61\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 62 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 63\n",
      "No src or srcset found for image 64\n",
      "No src or srcset found for image 65\n",
      "No src or srcset found for image 66\n",
      "No src or srcset found for image 67\n",
      "No src or srcset found for image 68\n",
      "No src or srcset found for image 69\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 70 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 71\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 72 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 73\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 74 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 75\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 76 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 77\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 78 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 79\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 80 in folder 'fidelio-notte-high-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "No src or srcset found for image 81\n",
      "No src or srcset found for image 82\n",
      "No src or srcset found for image 83\n",
      "Falling back to src image: data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "Error downloading image 84: Failed to parse: https://www.poltronafrau.comdata:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "Falling back to src image: data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "Error downloading image 85: Failed to parse: https://www.poltronafrau.comdata:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "Falling back to src image: data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "Error downloading image 86: Failed to parse: https://www.poltronafrau.comdata:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "Falling back to src image: data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "Error downloading image 87: Failed to parse: https://www.poltronafrau.comdata:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "Error clicking the 'Downloads' tab: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF69425B5D2+29090]\n",
      "\t(No symbol) [0x00007FF6941CE689]\n",
      "\t(No symbol) [0x00007FF69408B1CA]\n",
      "\t(No symbol) [0x00007FF6940DEFD7]\n",
      "\t(No symbol) [0x00007FF6940DF22C]\n",
      "\t(No symbol) [0x00007FF6941297F7]\n",
      "\t(No symbol) [0x00007FF69410672F]\n",
      "\t(No symbol) [0x00007FF6941265D9]\n",
      "\t(No symbol) [0x00007FF694106493]\n",
      "\t(No symbol) [0x00007FF6940D09B1]\n",
      "\t(No symbol) [0x00007FF6940D1B11]\n",
      "\tGetHandleVerifier [0x00007FF694578C5D+3295277]\n",
      "\tGetHandleVerifier [0x00007FF6945C4843+3605523]\n",
      "\tGetHandleVerifier [0x00007FF6945BA707+3564247]\n",
      "\tGetHandleVerifier [0x00007FF694316EB6+797318]\n",
      "\t(No symbol) [0x00007FF6941D980F]\n",
      "\t(No symbol) [0x00007FF6941D53F4]\n",
      "\t(No symbol) [0x00007FF6941D5580]\n",
      "\t(No symbol) [0x00007FF6941C4A1F]\n",
      "\tBaseThreadInitThunk [0x00007FF882337374+20]\n",
      "\tRtlUserThreadStart [0x00007FF882DBCC91+33]\n",
      "\n",
      "Found ZIP file download URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/20_area_professionals/planning-tools/professionals-fidelio-notte-high-drawer-chest_product-sheet.zip\n",
      "Failed to download ZIP file, status code: 403\n",
      "Primary download URL found: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/f/i/d/fidelio-notte-high-drawer-chest/20_area_professionals/planning-tools/professionals-fidelio-notte-high-drawer-chest_product-sheet.zip\n",
      "Successfully fetched the file.\n",
      "File downloaded and extracted successfully into the folder.\n",
      "Visiting product page: https://www.poltronafrau.com/ww/en/products/moondance-drawer-chest.html\n",
      "Falling back to src image: https://www.poltronafrau.com/content/experience-fragments/poltronafrau/ww/en/site/header/master/_jcr_content/root/header/logoImage.coreimg.65.768.jpeg/1690973285872/logo.jpeg\n",
      "Downloaded image 1 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/content/experience-fragments/poltronafrau/ww/en/site/header/master/_jcr_content/root/header/logoImage.coreimg.65.768.jpeg/1690973285872/logo.jpeg\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/heart2.svg\n",
      "Downloaded image 2 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/heart2.svg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/01_hero/moondance-drawer-chest-v1.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 3 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/01_hero/moondance-drawer-chest-v1.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "No src or srcset found for image 4\n",
      "No src or srcset found for image 5\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/01_moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 6 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/01_moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/02_moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 7 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/02_moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/03_moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 8 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/03_moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/04-moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 9 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/04-moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/05-moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 10 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/05-moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/06-moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 11 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/06-moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/07-moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 12 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/07-moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "No src or srcset found for image 13\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/02_moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 14 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/02_moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/03_moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 15 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/03_moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/04-moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 16 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/04-moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/05-moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 17 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/05-moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/06-moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 18 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/06-moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Highest resolution image URL: /content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/07-moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Downloaded image 19 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/content/dam/ld/poltronafrau/products/m/o/o/moondance-drawer-chest/02_thumbnails/07-moondance-drawer-chest.jpg/jcr:content/renditions/cq5dam.thumbnail.5616.5616.jpg\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/icon-rotate.svg\n",
      "Downloaded image 20 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/icon-rotate.svg\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/icon-gray-plus.svg\n",
      "Downloaded image 21 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/icon-gray-plus.svg\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/icon-gray-minus.svg\n",
      "Downloaded image 22 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/poltronafrau/clientlibs/clientlib-site/resources/icons/icon-gray-minus.svg\n",
      "No src or srcset found for image 23\n",
      "Falling back to src image: data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "Error downloading image 24: Failed to parse: https://www.poltronafrau.comdata:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n",
      "No src or srcset found for image 25\n",
      "No src or srcset found for image 26\n",
      "No src or srcset found for image 27\n",
      "No src or srcset found for image 28\n",
      "No src or srcset found for image 29\n",
      "No src or srcset found for image 30\n",
      "No src or srcset found for image 31\n",
      "No src or srcset found for image 32\n",
      "No src or srcset found for image 33\n",
      "No src or srcset found for image 34\n",
      "No src or srcset found for image 35\n",
      "No src or srcset found for image 36\n",
      "No src or srcset found for image 37\n",
      "No src or srcset found for image 38\n",
      "No src or srcset found for image 39\n",
      "No src or srcset found for image 40\n",
      "No src or srcset found for image 41\n",
      "No src or srcset found for image 42\n",
      "No src or srcset found for image 43\n",
      "No src or srcset found for image 44\n",
      "No src or srcset found for image 45\n",
      "No src or srcset found for image 46\n",
      "No src or srcset found for image 47\n",
      "No src or srcset found for image 48\n",
      "No src or srcset found for image 49\n",
      "No src or srcset found for image 50\n",
      "No src or srcset found for image 51\n",
      "No src or srcset found for image 52\n",
      "No src or srcset found for image 53\n",
      "No src or srcset found for image 54\n",
      "No src or srcset found for image 55\n",
      "No src or srcset found for image 56\n",
      "No src or srcset found for image 57\n",
      "No src or srcset found for image 58\n",
      "No src or srcset found for image 59\n",
      "No src or srcset found for image 60\n",
      "No src or srcset found for image 61\n",
      "No src or srcset found for image 62\n",
      "No src or srcset found for image 63\n",
      "No src or srcset found for image 64\n",
      "No src or srcset found for image 65\n",
      "No src or srcset found for image 66\n",
      "No src or srcset found for image 67\n",
      "No src or srcset found for image 68\n",
      "No src or srcset found for image 69\n",
      "No src or srcset found for image 70\n",
      "No src or srcset found for image 71\n",
      "No src or srcset found for image 72\n",
      "No src or srcset found for image 73\n",
      "No src or srcset found for image 74\n",
      "No src or srcset found for image 75\n",
      "No src or srcset found for image 76\n",
      "No src or srcset found for image 77\n",
      "No src or srcset found for image 78\n",
      "No src or srcset found for image 79\n",
      "No src or srcset found for image 80\n",
      "No src or srcset found for image 81\n",
      "No src or srcset found for image 82\n",
      "No src or srcset found for image 83\n",
      "No src or srcset found for image 84\n",
      "No src or srcset found for image 85\n",
      "No src or srcset found for image 86\n",
      "No src or srcset found for image 87\n",
      "No src or srcset found for image 88\n",
      "No src or srcset found for image 89\n",
      "No src or srcset found for image 90\n",
      "No src or srcset found for image 91\n",
      "No src or srcset found for image 92\n",
      "No src or srcset found for image 93\n",
      "No src or srcset found for image 94\n",
      "No src or srcset found for image 95\n",
      "No src or srcset found for image 96\n",
      "No src or srcset found for image 97\n",
      "Falling back to src image: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n",
      "Downloaded image 98 in folder 'moondance-drawer-chest' from URL: https://www.poltronafrau.com/etc.clientlibs/cassina/clientlibs/clientlib-site/resources/icons/ico-download.svg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import zipfile\n",
    "import urllib.request\n",
    "from io import BytesIO\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# Path to your WebDriver executable\n",
    "webdriver_path = 'D:/Internship_Developers_den/web_scraping/folder_driver/chromedriver-win64/chromedriver.exe'\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Uncomment if you want to run it headlessly\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(webdriver_path), options=chrome_options)\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    \"\"\" Remove or replace invalid characters from filenames/folders \"\"\"\n",
    "    invalid_chars = '<>:\"/\\\\|?*'\n",
    "    for char in invalid_chars:\n",
    "        filename = filename.replace(char, '_')\n",
    "    return filename\n",
    "\n",
    "def download_image(image_url, folder_name, idx):\n",
    "    try:\n",
    "        # Ensure the image URL is absolute\n",
    "        if not image_url.startswith(\"http\"):\n",
    "            image_url = \"https://www.poltronafrau.com\" + image_url\n",
    "\n",
    "        # Create the download folder using the sanitized folder name\n",
    "        download_folder = os.path.join(os.getcwd(), folder_name)\n",
    "        os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "        # Download the image\n",
    "        response = requests.get(image_url)\n",
    "        if response.status_code == 200:\n",
    "            image_path = os.path.join(download_folder, f'image_{idx + 1}.png')\n",
    "            with open(image_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Downloaded image {idx + 1} in folder '{folder_name}' from URL: {image_url}\")\n",
    "        else:\n",
    "            print(f\"Failed to download image {idx + 1}, status code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image {idx + 1}: {e}\")\n",
    "\n",
    "def download_images_from_product_page(folder_name):\n",
    "    try:\n",
    "        # Locate the image elements with the srcset attribute\n",
    "        img_selector = \"img.cmp-image__image\"\n",
    "        image_elements = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, img_selector))\n",
    "        )\n",
    "\n",
    "        for idx, img_element in enumerate(image_elements):\n",
    "            # Extract the srcset attribute (which contains URLs for different image resolutions)\n",
    "            srcset = img_element.get_attribute('srcset')\n",
    "            if not srcset:\n",
    "                # Fallback to data-srcset if srcset is not present\n",
    "                srcset = img_element.get_attribute('data-srcset')\n",
    "\n",
    "            if srcset:\n",
    "                # Split the srcset string into individual image URLs and resolutions\n",
    "                srcset_items = [item.strip() for item in srcset.split(\",\")]\n",
    "\n",
    "                # Extract the highest resolution image (assuming it's the last in the srcset)\n",
    "                highest_res_image = srcset_items[-1].split()[0]\n",
    "                print(f\"Highest resolution image URL: {highest_res_image}\")\n",
    "\n",
    "                # Download the highest-resolution image\n",
    "                download_image(highest_res_image, folder_name, idx)\n",
    "            else:\n",
    "                # If no srcset is found, attempt to download the standard src image\n",
    "                src = img_element.get_attribute('src')\n",
    "                if src:\n",
    "                    print(f\"Falling back to src image: {src}\")\n",
    "                    download_image(src, folder_name, idx)\n",
    "                else:\n",
    "                    print(f\"No src or srcset found for image {idx + 1}\")\n",
    "\n",
    "    except TimeoutException as e:\n",
    "        print(f\"Error locating images: {e}\")\n",
    "\n",
    "def get_folder_name_from_url(product_url):\n",
    "    \"\"\"Extract folder name from the product URL\"\"\"\n",
    "    try:\n",
    "        # Extract the folder name from the URL after 'products/' and before '.html'\n",
    "        part_after_products = product_url.split('products/')[1]\n",
    "        folder_name = part_after_products.split('.html')[0]\n",
    "        return sanitize_filename(folder_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting folder name: {e}\")\n",
    "        return \"default_folder\"\n",
    "\n",
    "def visit_product_page_and_download_images(product_url):\n",
    "    try:\n",
    "        print(f\"Visiting product page: {product_url}\")\n",
    "        driver.get(product_url)\n",
    "\n",
    "        # Wait for the page to load\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Get the folder name based on the product URL\n",
    "        folder_name = get_folder_name_from_url(product_url)\n",
    "\n",
    "        # Download images from the product page\n",
    "        download_images_from_product_page(folder_name)\n",
    "\n",
    "        # After downloading images, click on the \"Downloads\" tab\n",
    "        click_download_tab()\n",
    "\n",
    "        # After clicking the download tab, download the ZIP file and extract its contents\n",
    "        download_and_extract_zip_file(folder_name)\n",
    "\n",
    "        # Download additional files if available\n",
    "        download_additional_files(folder_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error visiting product page {product_url}: {e}\")\n",
    "\n",
    "def click_download_tab():\n",
    "    \"\"\"Clicks the 'Downloads' tab based on the provided selector\"\"\"\n",
    "    try:\n",
    "        # Wait for the tab element to be clickable and then click it\n",
    "        tab_selector = \"#producttabs-3baf65de06-item-25a16ecc4d-tab\"\n",
    "        download_tab = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, tab_selector))\n",
    "        )\n",
    "        download_tab.click()\n",
    "        print(\"Successfully clicked the 'Downloads' tab.\")\n",
    "        \n",
    "    except TimeoutException as e:\n",
    "        print(f\"Error clicking the 'Downloads' tab: {e}\")\n",
    "\n",
    "def download_and_extract_zip_file(folder_name):\n",
    "    \"\"\"Download the ZIP file from the newly appeared <a> tag and extract it into the same folder\"\"\"\n",
    "    try:\n",
    "        # Wait for the <a> tag to become visible\n",
    "        a_tag_selector = \"#professionals > div > div > div:nth-child(1) > div > h3 > button > a\"\n",
    "        a_tag_element = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, a_tag_selector))\n",
    "        )\n",
    "\n",
    "        # Get the URL from the href attribute\n",
    "        file_url = a_tag_element.get_attribute('href')\n",
    "        if file_url:\n",
    "            print(f\"Found ZIP file download URL: {file_url}\")\n",
    "\n",
    "            # Create a downloads folder if it doesn't exist\n",
    "            download_folder = os.path.join(os.getcwd(), folder_name)\n",
    "            os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "            # Download the ZIP file with headers and cookies\n",
    "            headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36',\n",
    "                'Referer': driver.current_url,\n",
    "            }\n",
    "            # Extract cookies from the Selenium session\n",
    "            cookies = {cookie['name']: cookie['value'] for cookie in driver.get_cookies()}\n",
    "\n",
    "            # Download the ZIP file\n",
    "            response = requests.get(file_url, headers=headers, cookies=cookies)\n",
    "            if response.status_code == 200:\n",
    "                # Extract the ZIP file in-memory\n",
    "                with zipfile.ZipFile(BytesIO(response.content)) as zip_file:\n",
    "                    # Extract all contents to the download folder\n",
    "                    zip_file.extractall(download_folder)\n",
    "                    print(f\"Extracted ZIP contents to folder '{folder_name}'\")\n",
    "\n",
    "                    # Process the PDF file inside the ZIP file\n",
    "                    for file_name in zip_file.namelist():\n",
    "                        if file_name.endswith('.pdf'):\n",
    "                            pdf_path = os.path.join(download_folder, file_name)\n",
    "                            print(f\"Found PDF file: {pdf_path}\")\n",
    "                            # Process the PDF file as needed (e.g., move, read, etc.)\n",
    "            else:\n",
    "                print(f\"Failed to download ZIP file, status code: {response.status_code}\")\n",
    "        else:\n",
    "            print(\"No href found for the download link.\")\n",
    "        \n",
    "    except TimeoutException as e:\n",
    "        print(f\"Error locating the download link: {e}\")\n",
    "\n",
    "\n",
    "def download_additional_files(folder_name):\n",
    "    \"\"\"Download additional files linked in the product page from multiple possible selectors\"\"\"\n",
    "    try:\n",
    "        # Define selectors to attempt\n",
    "        primary_selector = '#professionals > div > div > div:nth-child(1) > div > h3 > button > a'\n",
    "        secondary_selector = '#professionals > div > div > div:nth-child(1) > div:nth-child(2) > h3 > button > a'\n",
    "        \n",
    "        download_url = None\n",
    "\n",
    "        # Attempt to find and click the primary selector\n",
    "        try:\n",
    "            download_button = WebDriverWait(driver, 20).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, primary_selector))\n",
    "            )\n",
    "            download_url = download_button.get_attribute('href')\n",
    "            print(f\"Primary download URL found: {download_url}\")\n",
    "        except TimeoutException:\n",
    "            print(\"Primary download button not found, trying secondary selector.\")\n",
    "\n",
    "        # If primary selector fails, attempt to find and click the secondary selector\n",
    "        if not download_url:\n",
    "            try:\n",
    "                download_button = WebDriverWait(driver, 20).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, secondary_selector))\n",
    "                )\n",
    "                download_url = download_button.get_attribute('href')\n",
    "                print(f\"Secondary download URL found: {download_url}\")\n",
    "            except TimeoutException:\n",
    "                print(\"Secondary download button not found or the page took too long to load.\")\n",
    "                return  # Exit if neither URL is found\n",
    "\n",
    "        # Download the ZIP file using urllib and custom headers to bypass protection\n",
    "        if download_url:\n",
    "            req = urllib.request.Request(download_url)\n",
    "            req.add_header('User-Agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:106.0) Gecko/20100101 Firefox/106.0')\n",
    "            req.add_header('Accept', 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8')\n",
    "            req.add_header('Accept-Language', 'en-US,en;q=0.5')\n",
    "\n",
    "            # Open the URL and read the response\n",
    "            with urllib.request.urlopen(req) as response:\n",
    "                if response.status == 200:\n",
    "                    print(\"Successfully fetched the file.\")\n",
    "                    zip_data = response.read()\n",
    "\n",
    "                    # Define the path for saving the ZIP file\n",
    "                    zip_file_path = os.path.join(os.getcwd(), folder_name, 'additional_files.zip')\n",
    "                    with open(zip_file_path, 'wb') as f:\n",
    "                        f.write(zip_data)\n",
    "\n",
    "                    # Extract the ZIP file into the folder\n",
    "                    with zipfile.ZipFile(zip_file_path) as z:\n",
    "                        z.extractall(os.path.join(os.getcwd(), folder_name))\n",
    "                    print(\"File downloaded and extracted successfully into the folder.\")\n",
    "                else:\n",
    "                    print(f\"Failed to download the file. Status code: {response.status}\")\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"Download button not found or the page took too long to load.\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    list_page_url = 'https://www.poltronafrau.com/ww/en/products/products.87.html?_gl=1*7lpixs*_up*MQ..*_ga*MTkwNTg1OTczLjE3MjYwNDI4MDY.*_ga_YGJJL14S4G*MTcyNjA0MjgwNS4xLjAuMTcyNjA0MjgwNS4wLjAuMA..&selectedFilters=pf_info_categoria&pf_info_categoria=11307'\n",
    "    \n",
    "    # Extract and save all product links\n",
    "    product_links = extract_product_links(list_page_url)\n",
    "\n",
    "    # Read the product links from the file and visit each page\n",
    "    with open('product_links.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            product_url = line.strip()\n",
    "            if product_url:\n",
    "                visit_product_page_and_download_images(product_url)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
